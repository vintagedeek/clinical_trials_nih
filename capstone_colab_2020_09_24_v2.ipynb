{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "capstone_colab_2020_09_24_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1IWrqwy8iBvRt0izcyAu9wQTljh6IiQgl",
      "authorship_tag": "ABX9TyOSWjAfCM1EPcyRMU3MmrJR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vintagedeek/clinical_trials_nih/blob/master/capstone_colab_2020_09_24_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U9kTxLiJ40b"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from torchtext import data, datasets, vocab\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import spacy\n",
        "\n",
        "from collections import OrderedDict, namedtuple\n",
        "from itertools import product\n",
        "import time\n",
        "\n",
        "import random, math\n",
        "import tqdm, sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AitxhrLKKEJp"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rhk25vcmEzo"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvs3D4u0mQhN"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1Ipvu3ZmSRL",
        "outputId": "4a146f1e-2d5f-40f2-a5b0-22e757cc9c32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z2Lh7pImVZo",
        "outputId": "4f43b225-5ee2-4468-88d2-665089f013de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        }
      },
      "source": [
        "!ls /content/gdrive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"2016 - Evan's 3rd Birthday\"\n",
            " ACCP\n",
            "'Colab Notebooks'\n",
            " DSC_0148.JPG\n",
            " DSC_0162.JPG\n",
            " DSC_0164.JPG\n",
            " DSC_0166.JPG\n",
            " DSC_0168.JPG\n",
            " DSC_0176.JPG\n",
            " DSC_0196.JPG\n",
            " DSC_0199.JPG\n",
            " DSC_0210.JPG\n",
            " DSC_0231.JPG\n",
            " DSC_0246.JPG\n",
            " DSC_0251.JPG\n",
            " DSC_0264.JPG\n",
            " DSC_0265.JPG\n",
            " DSC_0266.JPG\n",
            " DSC_0270.JPG\n",
            " DSC_0274.JPG\n",
            " DSC_0275.JPG\n",
            " DSC_0304.JPG\n",
            " DSC_0310.JPG\n",
            " DSC_0312.JPG\n",
            " DSC_0317.JPG\n",
            " DSC_0318.JPG\n",
            " DSC_0320.JPG\n",
            " DSC_0321.JPG\n",
            "'family_health_data_based_on_relation_to_aunt_sandie_2020_07_08 (1).gsheet'\n",
            " family_health_data_based_on_relation_to_aunt_sandie_2020_07_08.gsheet\n",
            " final_2019_ascending.mp4\n",
            " Image-1.jpg\n",
            " IMG_6232.jpg\n",
            " IMG_6892.jpg\n",
            " MidwesternTranscriptGriffing.gdoc\n",
            " MidwesternTranscriptGriffing.pdf\n",
            "'Mortgage Suntrust'\n",
            " savannah_cutest_laugh_6mo.MOV\n",
            " test_colab.csv\n",
            " train_colab.csv\n",
            "'Untitled spreadsheet.gsheet'\n",
            " val_colab.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bGL7DlBmh9B",
        "outputId": "0447ffee-fc5b-4d83-d893-2190bc622f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  gdrive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npcBJCmXmXYf"
      },
      "source": [
        "train_url1 = 'https://raw.githubusercontent.com/vintagedeek/clinical_trials_nih/master/data_capstone/train1.csv'\n",
        "train_url2 = 'https://raw.githubusercontent.com/vintagedeek/clinical_trials_nih/master/data_capstone/train2.csv'\n",
        "train_url3 = 'https://raw.githubusercontent.com/vintagedeek/clinical_trials_nih/master/data_capstone/train3.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQlI3T5SmY6H",
        "outputId": "f5335a2b-55fa-41ef-b25f-f959f715bb67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df_train1 = pd.read_csv(train_url1)\n",
        "df_train2 = pd.read_csv(train_url2)\n",
        "df_train3 = pd.read_csv(train_url3)\n",
        "df_train = pd.concat([df_train1, df_train2, df_train3])\n",
        "len(df_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131562"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciS1H6CYmeEn"
      },
      "source": [
        "df_train.to_csv('train_colab.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaRUhKA8ma2G"
      },
      "source": [
        "val_url = 'https://raw.githubusercontent.com/vintagedeek/clinical_trials_nih/master/data_capstone/val.csv'\n",
        "test_url = 'https://raw.githubusercontent.com/vintagedeek/clinical_trials_nih/master/data_capstone/test.csv'\n",
        "df_val = pd.read_csv(val_url)\n",
        "df_test = pd.read_csv(test_url)\n",
        "df_val.to_csv('val_colab.csv', index=False)\n",
        "df_test.to_csv('test_colab.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn1h9YxAmp92"
      },
      "source": [
        "# Tokenize Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyytJwWTmaTC"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EkVrAlFmsh4"
      },
      "source": [
        "def tokenizer(text): # create a tokenizer function\n",
        "    return [tok.text for tok in nlp.tokenizer(text)] # tok.text returns the string of each word; otherwise just having tok would give a type == spacy.tokens.token.Token"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cpVCtMdmu36"
      },
      "source": [
        "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, include_lengths=True, batch_first=True)\n",
        "LABEL = data.Field(sequential=False, use_vocab=True) # use_vocab when labels are strings. set use_vocab=False if labels are already integers."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV-HDR1smwZn"
      },
      "source": [
        "train, val, test = data.TabularDataset.splits(path='gdrive/My Drive/', train='train_colab.csv', validation='val_colab.csv', \n",
        "                                              test='test_colab.csv', format='csv', fields=[('text', TEXT), ('units_clean', LABEL)],\n",
        "                                              skip_header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9TBm46xmuEO"
      },
      "source": [
        "# Word embeddings? (don't think...seems to happen in model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2fScXzjm2Yv"
      },
      "source": [
        "TEXT.build_vocab(train, max_size=50_000 - 2) # 50000 is vocab size - minus 2 to make space for <unk> and <pad>\n",
        "LABEL.build_vocab(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bQwAP0vm60e"
      },
      "source": [
        "# Batching Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka6vZV81m396"
      },
      "source": [
        "# Replaced PB code with code from link\n",
        "train_iter, val_iter = data.BucketIterator.splits((train, val), batch_size=4, device=device,\n",
        "                                                  sort_key=lambda x: len(x.text), #  https://github.com/pytorch/text/issues/474\n",
        "                                                  sort_within_batch=False) # per link above, False bc w want to wrap this Iterator layer. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l8qfu7pm5Q4"
      },
      "source": [
        "mx = 512 # mx is max length, Peter Bloem set to 512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqHC4-Pkm_z7"
      },
      "source": [
        "# Peter Bloem Self Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akEhV_bTnCLw"
      },
      "source": [
        "class SelfAttentionWide(nn.Module):\n",
        "    def __init__(self, emb, heads=8, mask=False):\n",
        "        \"\"\"\n",
        "        :param emb:\n",
        "        :param heads:\n",
        "        :param mask:\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb = emb\n",
        "        self.heads = heads\n",
        "        self.mask = mask\n",
        "\n",
        "        self.tokeys = nn.Linear(emb, emb * heads, bias=False)\n",
        "        self.toqueries = nn.Linear(emb, emb * heads, bias=False)\n",
        "        self.tovalues = nn.Linear(emb, emb * heads, bias=False)\n",
        "\n",
        "        self.unifyheads = nn.Linear(heads * emb, emb)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        b, t, e = x.size()\n",
        "        h = self.heads\n",
        "        assert e == self.emb, f'Input embedding dim ({e}) should match layer embedding dim ({self.emb})'\n",
        "\n",
        "        keys    = self.tokeys(x)   .view(b, t, h, e)\n",
        "        queries = self.toqueries(x).view(b, t, h, e)\n",
        "        values  = self.tovalues(x) .view(b, t, h, e)\n",
        "\n",
        "        # compute scaled dot-product self-attention\n",
        "\n",
        "        # - fold heads into the batch dimension\n",
        "        keys = keys.transpose(1, 2).contiguous().view(b * h, t, e)\n",
        "        queries = queries.transpose(1, 2).contiguous().view(b * h, t, e)\n",
        "        values = values.transpose(1, 2).contiguous().view(b * h, t, e)\n",
        "\n",
        "        queries = queries / (e ** (1/4))\n",
        "        keys    = keys / (e ** (1/4))\n",
        "        # - Instead of dividing the dot products by sqrt(e), we scale the keys and values.\n",
        "        #   This should be more memory efficient\n",
        "\n",
        "        # - get dot product of queries and keys, and scale\n",
        "        dot = torch.bmm(queries, keys.transpose(1, 2))\n",
        "\n",
        "        assert dot.size() == (b*h, t, t)\n",
        "\n",
        "        if self.mask: # mask out the upper half of the dot matrix, excluding the diagonal\n",
        "            mask_(dot, maskval=float('-inf'), mask_diagonal=False)\n",
        "\n",
        "        dot = F.softmax(dot, dim=2)\n",
        "        # - dot now has row-wise self-attention probabilities\n",
        "\n",
        "        # apply the self attention to the values\n",
        "        out = torch.bmm(dot, values).view(b, h, t, e)\n",
        "\n",
        "        # swap h, t back, unify heads\n",
        "        out = out.transpose(1, 2).contiguous().view(b, t, h * e)\n",
        "\n",
        "        return self.unifyheads(out)\n",
        "\n",
        "class SelfAttentionNarrow(nn.Module):\n",
        "\n",
        "    def __init__(self, emb, heads=8, mask=False):\n",
        "        \"\"\"\n",
        "        :param emb:\n",
        "        :param heads:\n",
        "        :param mask:\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        assert emb % heads == 0, f'Embedding dimension ({emb}) should be divisible by nr. of heads ({heads})'\n",
        "\n",
        "        self.emb = emb\n",
        "        self.heads = heads\n",
        "        self.mask = mask\n",
        "\n",
        "        s = emb // heads\n",
        "        # - We will break the embedding into `heads` chunks and feed each to a different attention head\n",
        "\n",
        "        self.tokeys    = nn.Linear(s, s, bias=False)\n",
        "        self.toqueries = nn.Linear(s, s, bias=False)\n",
        "        self.tovalues  = nn.Linear(s, s, bias=False)\n",
        "\n",
        "        self.unifyheads = nn.Linear(heads * s, emb)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        b, t, e = x.size()\n",
        "        h = self.heads\n",
        "        assert e == self.emb, f'Input embedding dim ({e}) should match layer embedding dim ({self.emb})'\n",
        "\n",
        "        s = e // h\n",
        "        x = x.view(b, t, h, s)\n",
        "\n",
        "        keys    = self.tokeys(x)\n",
        "        queries = self.toqueries(x)\n",
        "        values  = self.tovalues(x)\n",
        "\n",
        "        assert keys.size() == (b, t, h, s)\n",
        "        assert queries.size() == (b, t, h, s)\n",
        "        assert values.size() == (b, t, h, s)\n",
        "\n",
        "        # Compute scaled dot-product self-attention\n",
        "\n",
        "        # - fold heads into the batch dimension\n",
        "        keys = keys.transpose(1, 2).contiguous().view(b * h, t, s)\n",
        "        queries = queries.transpose(1, 2).contiguous().view(b * h, t, s)\n",
        "        values = values.transpose(1, 2).contiguous().view(b * h, t, s)\n",
        "\n",
        "        queries = queries / (e ** (1/4))\n",
        "        keys    = keys / (e ** (1/4))\n",
        "        # - Instead of dividing the dot products by sqrt(e), we scale the keys and values.\n",
        "        #   This should be more memory efficient\n",
        "\n",
        "        # - get dot product of queries and keys, and scale\n",
        "        dot = torch.bmm(queries, keys.transpose(1, 2))\n",
        "\n",
        "        assert dot.size() == (b*h, t, t)\n",
        "\n",
        "        if self.mask: # mask out the upper half of the dot matrix, excluding the diagonal\n",
        "            mask_(dot, maskval=float('-inf'), mask_diagonal=False)\n",
        "\n",
        "        dot = F.softmax(dot, dim=2)\n",
        "        # - dot now has row-wise self-attention probabilities\n",
        "\n",
        "        # apply the self attention to the values\n",
        "        out = torch.bmm(dot, values).view(b, h, t, s)\n",
        "\n",
        "        # swap h, t back, unify heads\n",
        "        out = out.transpose(1, 2).contiguous().view(b, t, s * h)\n",
        "\n",
        "        return self.unifyheads(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG7h3gUnnJx0"
      },
      "source": [
        "# Peter Bloem Transformer Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1B2OKo6nDPo"
      },
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, emb, heads, mask, seq_length, ff_hidden_mult=4, dropout=0.0, wide=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attention = SelfAttentionWide(emb, heads=heads, mask=mask) if wide \\\n",
        "                    else SelfAttentionNarrow(emb, heads=heads, mask=mask)\n",
        "        self.mask = mask\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(emb)\n",
        "        self.norm2 = nn.LayerNorm(emb)\n",
        "\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(emb, ff_hidden_mult * emb),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ff_hidden_mult * emb, emb)\n",
        "        )\n",
        "\n",
        "        self.do = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        attended = self.attention(x)\n",
        "\n",
        "        x = self.norm1(attended + x)\n",
        "\n",
        "        x = self.do(x)\n",
        "\n",
        "        fedforward = self.ff(x)\n",
        "\n",
        "        x = self.norm2(fedforward + x)\n",
        "\n",
        "        x = self.do(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nekzEXlFnM-u"
      },
      "source": [
        "# Peter Bloem Classification Transformer Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6koMWxInPIw"
      },
      "source": [
        "class CTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer for classifying sequences\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, emb, heads, depth, seq_length, num_tokens, num_classes, max_pool=True, dropout=0.0, wide=False):\n",
        "        \"\"\"\n",
        "        :param emb: Embedding dimension\n",
        "        :param heads: nr. of attention heads\n",
        "        :param depth: Number of transformer blocks\n",
        "        :param seq_length: Expected maximum sequence length\n",
        "        :param num_tokens: Number of tokens (usually words) in the vocabulary\n",
        "        :param num_classes: Number of classes.\n",
        "        :param max_pool: If true, use global max pooling in the last layer. If false, use global\n",
        "                         average pooling.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_tokens, self.max_pool = num_tokens, max_pool\n",
        "\n",
        "        self.token_embedding = nn.Embedding(embedding_dim=emb, num_embeddings=num_tokens)\n",
        "        self.pos_embedding = nn.Embedding(embedding_dim=emb, num_embeddings=seq_length)\n",
        "\n",
        "        tblocks = []\n",
        "        for i in range(depth):\n",
        "            tblocks.append(\n",
        "                TransformerBlock(emb=emb, heads=heads, seq_length=seq_length, mask=False, dropout=dropout, wide=wide))\n",
        "\n",
        "        self.tblocks = nn.Sequential(*tblocks)\n",
        "\n",
        "        self.toprobs = nn.Linear(emb, num_classes)\n",
        "\n",
        "        self.do = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        :param x: A batch by sequence length integer tensor of token indices.\n",
        "        :return: predicted log-probability vectors for each token based on the preceding tokens.\n",
        "        \"\"\"\n",
        "        tokens = self.token_embedding(x)\n",
        "        b, t, e = tokens.size()\n",
        "\n",
        "        positions = self.pos_embedding(torch.arange(t, device=device))[None, :, :].expand(b, t, e)\n",
        "        x = tokens + positions\n",
        "        x = self.do(x)\n",
        "\n",
        "        x = self.tblocks(x)\n",
        "\n",
        "        x = x.max(dim=1)[0] if self.max_pool else x.mean(dim=1) # pool over the time dimension\n",
        "\n",
        "        x = self.toprobs(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCNEUrwMnQMx",
        "outputId": "94f7aa41-eca5-41f2-827e-5a8bcdedf699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHrI6JhznRzW"
      },
      "source": [
        "model = CTransformer(emb=128, heads=8, depth=6, seq_length=mx, num_tokens=50000, num_classes=20, max_pool=True) # mx default 512\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8sHeHsOpAhS"
      },
      "source": [
        "opt = torch.optim.Adam(lr=0.0001, params=model.parameters())\n",
        "sch = torch.optim.lr_scheduler.LambdaLR(opt, lambda i: min(i / (10_000 / 4), 1.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRF6g83xkwo4"
      },
      "source": [
        "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
        "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
        "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
        "    empty_cell = \" \" * columnwidth\n",
        "    # Print header\n",
        "    print(\"    \" + empty_cell, end=\" \")\n",
        "    for label in labels:\n",
        "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
        "    print()\n",
        "    # Print rows\n",
        "    for i, label1 in enumerate(labels):\n",
        "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
        "        for j in range(len(labels)):\n",
        "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
        "            if hide_zeroes:\n",
        "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
        "            if hide_diagonal:\n",
        "                cell = cell if i != j else empty_cell\n",
        "            if hide_threshold:\n",
        "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
        "            print(cell, end=\" \")\n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vu12EDbunURM",
        "outputId": "2bdb1fc6-06de-42cd-f1f7-24b697d449b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        }
      },
      "source": [
        "seen = 0\n",
        "nb_classes = 20\n",
        "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
        "num_epochs = 11\n",
        "\n",
        "preds = np.zeros(0) # creates empty array for F1 score\n",
        "lab = np.zeros(0) # creates empty array for F1 score\n",
        "\n",
        "for e in range(num_epochs): # epochs\n",
        "\n",
        "    print(f'\\n epoch {e}')\n",
        "    model.train(True)\n",
        "\n",
        "    for batch in tqdm.tqdm(train_iter):\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        input = batch.text[0].to(device)\n",
        "        label = (batch.units_clean - 1).to(device)\n",
        "        \n",
        "        if input.size(1) > mx:\n",
        "            input = input[:, :mx]\n",
        "        out = model(input)\n",
        "        loss = F.nll_loss(out, label)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # clip gradients\n",
        "        # - If the total gradient vector has a length > 1, we clip it back down to 1.\n",
        "        if 1.0 > 0.0: # gradient_clipping arg default=1.0\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        opt.step()\n",
        "        sch.step()\n",
        "\n",
        "        seen += input.size(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      \n",
        "        model.train(False)\n",
        "        tot, cor= 0.0, 0.0\n",
        "\n",
        "        for batch in val_iter:\n",
        "\n",
        "            input = batch.text[0].to(device)\n",
        "            label = (batch.units_clean - 1).to(device)\n",
        "            \n",
        "            if input.size(1) > mx:\n",
        "                input = input[:, :mx]\n",
        "            out = model(input).argmax(dim=1)\n",
        "\n",
        "            tot += float(input.size(0))\n",
        "            cor += float((label == out).sum().item())\n",
        "            \n",
        "            if e == num_epochs - 1:\n",
        "                for t, p in zip(label.view(-1), out.view(-1)):\n",
        "                    confusion_matrix[t.long(), p.long()] += 1\n",
        "                \n",
        "                preds = np.append(preds, out.cpu().numpy())\n",
        "                lab = np.append(lab, label.cpu().numpy())\n",
        "\n",
        "        acc = cor / tot\n",
        "        print(f'-- {\"validation\"} accuracy {acc:.3}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [15:09<00:00, 36.17it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.866\n",
            "\n",
            " epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [15:03<00:00, 36.40it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.884\n",
            "\n",
            " epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [15:07<00:00, 36.23it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.891\n",
            "\n",
            " epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [15:00<00:00, 36.51it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.901\n",
            "\n",
            " epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [14:58<00:00, 36.59it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.904\n",
            "\n",
            " epoch 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [14:53<00:00, 36.83it/s]\n",
            "  0%|          | 1/32891 [00:00<1:46:30,  5.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.906\n",
            "\n",
            " epoch 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [14:45<00:00, 37.13it/s]\n",
            "  0%|          | 1/32891 [00:00<1:47:55,  5.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.907\n",
            "\n",
            " epoch 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [14:38<00:00, 37.43it/s]\n",
            "  0%|          | 1/32891 [00:00<1:48:41,  5.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.902\n",
            "\n",
            " epoch 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [14:50<00:00, 36.94it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.907\n",
            "\n",
            " epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [14:53<00:00, 36.82it/s]\n",
            "  0%|          | 1/32891 [00:00<1:48:45,  5.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.91\n",
            "\n",
            " epoch 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [14:52<00:00, 36.87it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wZ6Lp17TEx-"
      },
      "source": [
        "# 91 percent accuracy - first run original params\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABQIAAAFBCAYAAAAsWtIQAAAgAElEQVR4Aey9za8kx3Wn7f/B9sKWXQub+rAk6osiRQiQAFEiBgYMmCAgj4djXPUVYdHQwoAWI0KEFo3bwBUpGbYHjYFNkO37alpttmRQL27r7ekWZmHagNtoQd1oA1fUYmphre3NLLyOFxGRJ/PEV35UZVZlVT2LQlZlRkacOOeJyIxfRWT+0tNPP222/fnZz35mvvWtbxXt+OEPf2jsZ1N2/uEf/qH527/9W/ONb3xjI2X++Z//ufnpT39qXnzxxcHl/dVf/ZWxn035hnK2316IATGAARiAARiAARiAARiAARiAARiAARhYhYFfWuWksc/pEgK/+MUvGvsZu9xV8/vmN79p/uVf/sVYu+1Hi3g5Ue/OnTvGfnR59recH+dh09l89PH4fJ0X32n8MAADMAADMAADMAADMAADMAADMAADMAADXQzshBCoK/GXf/mX5nvf+5753Oc+FwhrOs2U30UEtEJdrpw+QqAV9f7xH//RPP/88y6P+Bw7M/Dv/u7v6vy7yszZwT4aPwzAAAzAAAzAAAzAAAzAAAzAAAzAAAzAgGZg54RAKwDevXvXfbYhBloRr212XizqWWfrc6zI98///M/GinsSiNw5csxurWBohcMbN27U5+jjfKdRwwAMwAAMwAAMwAAMwAAMwAAMwAAMwAAMdDGwE0Lg7/3e75nT09P6Y2cF2mWzVhDcpBjYR5DLiXpaCLQCoF1K3CUE2nP00mD7HSGQBt3VoDkOIzAAAzAAAzAAAzAAAzAAAzAAAzAAAyUGdkYItC8Tkc+2hEDrRC3q5Zw6hhBoBT/93ME+AmTOFvbR8GEABmAABmAABmAABmAABmAABmAABmAABoSBnRACxVi73fbSYCv02dl5dqvtku/xjD8r6tn0VkC0aWJRT/LTwp9Nq58hKHkwI5CGK5yxhQUYgAEYgAEYgAEYgAEYgAEYgAEYgIGhDOycELjtl4VYB4t4J0t3tYhnj+tlvfa7FfBECLTHrVgobx2259r87HMD7fMD7XG7tfslf3uu5GOP88EHMAADMAADMAADMAADMAADMAADMAADMAADQxnYCSHwi1/8orGfoZUjPQ0CBmAABmAABmAABmAABmAABmAABmAABmAABjwDOyEE/vCHPzT2Q9BouDAAAzAAAzAAAzAAAzAAAzAAAzAAAzAAAzCwGgOzEQKt0KffDKy//8M//ANCIEuCEYJhAAZgAAZgAAZgAAZgAAZgAAZgAAZgAAbWYGA2QqA8D6+0ZUbgakovCjl+gwEYgAEYgAEYgAEYgAEYgAEYgAEYgAEYsAzMQgj80pe+ZLo+PCMQYOm0YAAGYAAGYAAGYAAGYAAGYAAGYAAGYAAGVmdgFkIgAVw9gPgO38EADMAADMAADMAADMAADMAADMAADMAADPRhACFwjXXVfRxMGhoiDMAADMAADMAADMAADMAADMAADMAADMDAHBhACEQI5CGbMAADMAADMAADMAADMAADMAADMAADMAADB8AAQuABBHkOijM28M8HDMAADMAADMAADMAADMAADMAADMAADGyXAYRAhEAUfxiAARiAARiAARiAARiAARiAARiAARiAgQNgACHwAIKM2r5dtR3/438YgAEYgAEYgAEYgAEYgAEYgAEYgIE5MIAQiBCI4g8DMAADMAADMAADMAADMAADMAADMAADMLDHDHzqU58y9oMQuMdBnoPSjA384wEDMAADMAADMAADMAADMAADMAADMAADm2dAxD+9RQhECETxhwEYgAEYgAEYgAEYgAEYgAEYgAEYgAEY2BMGtPBnvz/11FP1ByFwT4KMsr55ZR2f43MYgAEYgAEYgAEYgAEYgAEYgAEYgIE5MRCLgLFtCIEIgSj+MAADMAADMAADMAADMAADMAADMAADMAADe8CAngEYi4D2N0LgHgQ5F1j28Y8EDMAADMAADMAADMAADMAADMAADMAADBwOAzIb0C4FLsUdIRAhsAhHCRr2H04nQqyJNQzAAAzAAAzAAAzAAAzAAAzAAAzsBgMyG/DJJ58saj0IgQiBRTho6LvR0IkTcYIBGIABGIABGIABGIABGIABGICBw2ZAzwb85Cc/WdR6EAIRAotw0IkcdidC/Ik/DMAADMAADMAADMAADMAADMAADOwGA1oIfOKJJ4paD0IgQmARDhr7bjR24kScYAAGYAAGYAAGYAAGYAAGYAAGYOCwGRAh0C4LRghE7EPsgwEYgAEYgAEYgAEYgAEYgAEYgAEYgAEY2FMGZisEimFsP2XwAT6AARiAARiAARiAARiAARiAARiAARiAARhYlwH7pmD7sc8H/MQnPlEUfEdfGryu4ZwP/DAAAzAAAzAAAzAAAzAAAzAAAzAAAzAAAzDQn4GNCoEEpn9g8BW+ggEYgAEYgAEYgAEYgAEYgAEYgAEYgAEYGJOBjQmBYxpNXjQCGIABGIABGIABGIABGIABGIABGIABGIABGBjGwORCYFdAxAC2fo02fsAPMAADMAADMAADMAADMAADMAADMAADMAADUzBg3xYsbwz++Mc/Pu4zAnMiYJ9KiFFsfXDwA36AARiAARiAARiAARiAARiAARiAARiAARhYlwH7khD7eeKJJ8zHPvax6YRALQDmjBZD2PqA4Af8AAMwAAMwAAMwAAMwAAMwAAMwAAMwAAMwMCYDVgC0H/vG4I9+9KPjCYF6NqCIgM8//7zZpc9isTB88AEMwAAMwAAMwAAMwAAMwAAMwAAMwAAMwMC+MPCbv/mbxn7e8573jCME5kRAOwtwl0RAa+u+BJh60FnBAAzAAAzAAAzAAAzAAAzAAAzAAAzAAAxYBiYTAmUmoBUB7TRGhECAo9OBARiAARiAARiAARiAARiAARiAARiAARjYHgOTCoEiAtq1xwiB2wsyDQzfwwAMwAAMwAAMwAAMwAAMwAAMwAAMwAAMjCoExsuCrRBoH0JoX0mMEAhsdDgwAAMwAAMwAAMwAAMwAAMwAAMwAAMwAAPbY2BSIdAuCbZCoH0TCULg9oJMA8P3MAADMAADMAADMAADMAADMAADMAADMAADkwmBelkwQiCg0dnAAAzAAAzAAAzAAAzAAAzAAAzAAAzAAAxslwEtBFrt7umnn04+v5TbmdsnS4Pti0JECLTLgj/ykY8wI3Cx3UDT0PA/DMAADMAADMAADMAADMAADMAADMAADMCAFQN/4zd+w3zgAx9IRECr960tBD7++OMIgQiBhs6GzgYGYAAGYAAGYAAGYAAGYAAGYAAGYAAGtsuACIG//uu/bt7//vcb+2g/PeEPIRARDxEPBmAABmAABmAABmAABmAABmAABmAABmBgDxgQIfA973mP+bVf+zXzq7/6q+ZXfuVXzC//8i+7Ty8hUJYF2228NJgZgdtVelHa8T8MwAAMwAAMwAAMwAAMwAAMwAAMwAAMwIAwIGKgXSJsZwbajxUF7WdlIdC+Mdg+I3BMIfBrX/uauX79unnw4EHwsfvssbHeTiyOyW3tGmo++AAGYAAGYAAGYAAGYGCbDLzwwgvuPnubNlA2bQAGYAAG9ouBH/6/bxv7Ia77FddcPO2SYPt53/ve5z7vfe97jXxmIQS+8sor5l//9V/Nf/zHf7R+3n33XWPTrisI5gRA2ZdzIPv2v5EQY2IMAzAAAzAAAzAwJwYQAuFxTjxiCzzCwH4wgBC4H3Ec0h5FENTbrQuBP/7xj1vFv5w4ePfu3bXEQBH9cltxaO4Y+5hmCwMwAAMwAAMwAAMwsAkGrBD42GOP8aymPXhW0yZ4oQz6JRiAgT4MiBDYJy1p9peprQqBP//5zweLgCIM2tmBq84MbAMaIXB/YW+LO8eIOwzAAAzAAAzAwJwYQAiExznxiC3wCAP7wQBC4H7Ecd32uDUhcJWZgCICynbVmYFtTkMIpGG08THPY8fmxoNH5saLxG6e8SEuxAUGYAAGYGA4AwiBw30GZ/hsXxg4vv7IPLp+zIxgZgSPzgBCIP2k7Se3IgTa5/yJmLfudpVnBrZdIKYRAo/M2b0Lc//a0YCGfGLOLy7MRfUZdu74cJ/camy5uLhvzi75Mo6u3a9tFFtlu22b2+Ic1ufcnOzsRcaKgEuzvHs6gK2efFw5NxcX4/jm2dffMLcf3jRvvf5MaufRy+athzfd8VIaOd8ed5+3x74x8u3t/EpP34zFy4g+Dni//FrtT+evd142z45lcymfqepSKs/tHzNuz5jL7zQc3h6dsQ2zVfBb2GeP074D9grlDk3j7Lx3Zo5Gym9o+aTP8+qunbdO0n58bnGKriv+2vGaeSmwM2rzuX4y6kuvXo79MkYecZ7N730TAnel/xmr/b/0trqmPIz5s3HuwU/AbMPGWDbuVT6Xzsx9NXYafk93xXz2zXfNH2Q/PzIf3ngsTs2d5dLceXX1uH/w618wR1/3jxd46tu/X3+fd9wfM59/c3VbbT2/+n35fNo8NWLcgrzffMJ8cMS865h84QlzVNvfUo9Ln/b1/PaHMtfkD5nndR5RGoTA1dtUHacpYr/hPLciBP7iF78oCoF2ufCQ2YKrLBFuC+B8hEABdBURUc4dZ+tFMz1gPDJnt9IB2q4MEPyNqK7POH5q42qqY/bfwuWDG+Z4io5jFGHH3+S+9frL5mpWCLTH3zCXj6oYVIM3PdhyImAwQDsu5LVOHMcUlAbYMYqPo/LcwFUPOKqBxtTC1hR1sVy7G/vmz4ewLY0Ut4q7rFA9RduaQ55TxWtA3dquGQiBUbse4NewjYT5rOvXtpi1lbvxY65N634w9IO1x4k0db+Y6SddHur65PpW9XukPNp8s29CYF3XGfQ/tS0jta0kP8tLzVfFW3Av04PBqWzb+3xHuDd4+rvmd9/8iXny6bTvSGI9pT9fvWOWy9VX/RyaEGjr+9Xvjyv+5eLtyikJgU7I+4L5/BdWZMed314HJ0h++wknmH41Evmsvfb489WkncXCi4IiCNvjCIErxmbKtr6FvDcuBH7ta18rioB2duBPf/pT9+y/v/iLvzD//u//3ppWZhPaPIc8LzDXoGUfQmDUMNzNWmkQHqbdlQHCrtgpTJa36/9TWM57YRYj3KhbEc+Lev3Fu3BwFt8oW+ZEXMzMLly5Ex3hpnGVskfwcRzDVDjN+TBsu3EeK/2eoC7Ojg0IgZa5gxIBLatTxWtAO2jri9cVrFZieIDtu5r/un5ti9msfNIlBMYin419JPTF1yK59tTizhh5dDCHEDjBtarD55NxHPMS/84wOJkt2/LBxsod4Z5uLkLgYmFO766+8scKQl4A8rPsGnFozm1r9RmBXiDLzZAbt75bFQIvfTqIaU4IjPuO2F6EwHF5iP29K783LgR+73vfaxX3RAi0wp4V+Pq8UMTmOZYQ+Mf/z31z8f/9T7eU1y5xPb/iLyZ6Oexi4WfpyRLY8FgFVjQ93aaNl8q6G+p6Cntphtp2ZwQOuekvpnW+sPUTX9plxnF9233qBi+3Tozbis+S5UlxHjZ+aUMv2uluULSNGTtb6+LLP78mSxPOzYkbbF+Yi2iJW3vsrQ1WfNX1yYix9l/CttmAEYMBf9aue2fmrFryff/aiWK+8pkIBVIH5/c4bql/853f6kLgwt0s36z/WffLhNtneuRtaLPVx71p7zb2GZ8HvsjwFfk8jru1K4x9iTG7Xz5Dfe59fVtmHkSD2+G+Kfutsy6t/hLOwzZXt9nYl7U/dF/aM26tgw/rr3CWz5g+0nnF/grapLUxqnNyvA8/rXVVsZT2nUvfakfVz13R/VOmLUSx9zz7NhX7Ice6CFYn+vETSZ+v6pPUo+Lrmn3Ege+D67wkn8rGwM/VvprDJN+2MvPHOq9fmVg4H2k7u/rrDjuDa6dqS0k/F8dNbKjyD+xSPAb+auUn1+67+9pcX6rbVvLdXTfK14n0D5NqRuDDm8GfV3p2uhcKbxrpW8fII7E7imMvIdDGzN5j6NgF9xy+rQacuxiJ36s23ePepcteezxu30G5Ur8M83Xeuh6W1YjB9B68R/8T+MO207D/yvIV25HkkW/vdT2krrKNhL9ufgbmL+Xora1Dn74jarOBP+SYjkO1LxtbXX79vWIsum4k58c+12W6vML7hXQsIT6TewP5vcK2RQj88Cvvmt/9ypfMe7/yk3oZsf0tsXf7/+y75r11/b9knvwzf46kWSz8vnoZcpA+stfNCrxjTuv8ouO5/bJsVC8Prb+3zzarbbR5vPmE+Xy11Pbo6x/yM9C+38w2c8Lb98PZb35fzzLE9sxyWD2DbbHw4mC95LcwG69dCIzyiOyOxTIpM7TD+z5NuzCLTB3E3lwetZ/FB7LtMSPQn1vVJzMjMM47thchsEcbknjs8XbjQqAV+mQmX26rhUAr7v3RH/1R51Lh+JwuUTBuHPq3EwKdACg3M/ZGSd9EVTcP+uLkLlxyQ9UM5pobY32+B8/dKKmbCn+Tnhvwp+dqe9u+F2/8Vblt59c3SrquLY0hHiDUectNROVXuz9Oe3TtvH7uYH1c2VnXRWyp8mx8nOZZl+9sjm8eRGRJRQV9Y5LEpbUuFRtO5KzKs3Vw5zR8dMe+sVVscXYof9i6tf5DmPjH5yn5+dlAvu7iW+vLIC5yQ1aXG7GvfNEM5K1fm7o2MegpBFaiXzD4cvFrBmkyCGvyHqMzF583tsdx8j5rjoto0zAYL5mPfC7c1/7Mzcry5zR5xnUTOxt+xffxOW42i3umYnkwvI4P8/5RfVhnvyh1aXyatDcb+6j9hDanecR2ud+B8FH5TvoSEQycYCrPcxpfGMy14aAuXW22Fz8xLy2/XXxUvKRv77RD+rlm8J3ELc6jEEMXG4mDlF9tpV+qRYBsnmk7aPqfio26D64EhbjemtO4jMimIF4DjnXWJbZJYi2+ccc7+uue9rRyqH3h8ov6/MiuuK05/yQ+9HGorz31H4JNu0/yKfBS+78qQ/q+ZtvkWf+BJM+VrQU+3yacCCPLNuvrjp5tHv5B4PpT++eK6yd8nzpGHnWdCvHrLQRWYrd/pmbscx/HJgZxvypt2vYHcbtRPi3YqOuQxLJ0ToZ5n8+JORfu7bkJT9F9Si7/Ln5EBFTlJHZ35dGHwci2mqFqfzc/Lf13lLeOQfC9V9/Rfe8SxiHmq4+dwlhz3UjuqTr7n7Tc5NpT+8Wnje+LpB5NnyHXkAznHUKgE/BEvIvSdguBlQj4ypVaPLTi4h9IfnU9xLd2BdAqy4O9UORnAdrloaFgF7CSlGnbn38GnRWxnJBUCYCx2OZ+V8KcT7eaCNjMVvR2N+JZKnjpMmXpq4huetvksTAf/Pqng+W6YR72+Bec8Nk89y+2Q+KRS9sc84LgQF9r/2cExcY3qhwRRzuFQJYGd7Ku/X9A32cvBIqo17ZUeHQh8J//p3tAubsxqG4U7Hd3E5W9OQhvstyFSd1giKDW3ITZC1R80SlctKobluZc3QFM/b26cAd1KZep/RU0uOqGSV+QWwcjtgFGN4lp+tDntjxXfjLTMLW3aGdUpq9DFJfWumib9Hk63vq72KbT2n3+dxDzxDb/kpDS28RSBhd+NqWIUCo/7dvgPJWmjqfdJ3kM6ij7CIGV2Ccz2er8/bl+OZYIgmMLNXEMUgbrPqC2q3tAErKWiX3iY29HLX6osuoYdO4L/SiCYCquCn+rbLvr0u2vjM8d+1HfmO1zxeZMHolPJW1hW4kA9XK/xcK4AVr2we6FPDpjUrW/pN9v8gvaXpWfbpu+X4h8M7Su2s7Cud126H6usj+Okc076Cf8OfoaUPfZhetLWHdbTqZcXZ/ku2JD2+e+hwKoL+vcnA9+qVcTv7b22VmXTCyCvkMd13m57wX/lezR58dpgjLFn6rsJmZnfgZ5EGPvi5xNYZkqLoUyZLAeXAMl7arbSuiXflBEmLCt+77TpxEhMLp22Xyqa9QYecQxiH/3FwJDpsNYZtqObhNB29Lxsd+jPqfN/0GeHW0j4iqud/M7td3Vre1ez9mh/+SNbMn0AZ45VdeuPNr8kDsW8Wfr181PZHcu3659ys+6HebaaePzwr1Nlde5XUkysN/J99/hdSFktqq7sj8eF3h7Na/aX6X9Ok3H90jc0/5JRTv/kpHPPufz7BQCXd7Ry0daylssVn0UkBL/es8yU35xQqAX9bRI5r4H4lMlmH370+ZoqNi4qES1XH7VS068sBaJi64+qdgWi5Q6bsl3VT97TNfRp92SEBi360qQTcXAVCBN6lg9LzB+biIzAhXnsb8P6PdOCYH/9m//lp1NuFEhUF+UFCj6Aqa/+wYZ3chUNxjpP1Lqn7I67+jcen83wO5Cn5sJk7l5z3Ucdl9al3K5xbSuvuoGK1eHrE+aG1t9A5P1aZWns0HqXKhnyc60DFvXyP+tddFp9U2IupnO1tP/I9kMkvW5JX+3C4GBH8QfesaA4ljX232XGzyVpuZD7yvWJRfraDCVMCACXzp7Lf4XPXlOU5JXyWdt+zM+13WtOMi1WX1D7Pyn/W2/iz9z7ARliH3eFikrHAyHxySN3Qo/4cDW55n6UMpacdtZF98WtH31d/FHJXiL3Z6xTBxyZdUxz6SPfFpsC2KHzAis87Q+8byKaFDzH6QZ7ruQj6Z/s/kX7ZR+LOeHqK6D7Cyc22lH3Cdan8S2ud8Nk8nMj8qPriyJQ+Rb3S/5eun+VcqU2Rx6K/2PYkPb576Hvpd+PhQvh8e35P/OumRiEfhGHdd5ue8F//W3ReoZ+VfioX0XcRq2XZ9PNz8qLlKGql9td8WQ9BtBWdExSdPMBpU66a2/xsizQH0/2Txywper273/fjt6bIA7TwuBdsahzCx09RmWR11f8UW03SkhMBfHqD51fVvS5hgKr4NRfyl9pC4rYiTgx5Wt+wz5Ln1HxU1bHtGxVgYrEVDYEx90M6j5XfG78nNb3+GOle5dlF99bOL+s49tuf5F79PfVX7Ozz4u2n7xofTdMR/yh3oQd1uPIXFrEeacEKhm8zX2eNs7hcDnflQvKa6XBrs3FZdeTjJcCHSCWL0UWN4867d6llxse/BbCWVaJEuFwGZZbO+8FVepeBcJcJUQpmf6+e8DhcDMTDstkOk6ej9Ediib07SK24JIGfhW5dW9v2RHtxDoOUj9hBCo4jUoFvt13uyFQLs0+O7du1kBUJYWb1QIVBelpuGGF7DgBt7BFR7PzuwoQhifu1kA/c1Bv4t+Wu/K1qzPdD38wCC4kKubF+vn9Aagyy/+eC3CKP8W7YzK9PGNBi2tddE26fPsd7nB1N+1D/R3fa7eH35vWxrs/NU2QFR11b4NzlNphHWdVvb12/rBUXwjLOf6WWupCFgS/Vz6YPAV+kby7b/N+Dyqv+UmYFQx5cpx6SXO3p6AtRw7URmJve4cJajEZWZ+50Q/PXhNysjk0ZmmR106/ZUTAnP55vbVNnfHrbMuTvSLZ5haXuN96zIWnu/YUAPYoO3V9VPn5PzQxU8uH9lXOLfTjgFCYDM4zjMctA+xq9qmfY3uX5VfovOaeCs2tO/c9/CaJnbItsmjTzndaTrrkolFYIs6rvPqjlVqmz4/rmdQpvhVlW3T12mcH9O4dtuk4lIoI7arJCQn6SS/7Da6Brk/AKI2Hv0pkLvO2H31dWyMPLK2NnHbKSFQt7OOeuVnd8nMad0+u9p9+V6v5sMxrK7NmT6gTluyO86jlC7e7xhRzOjjPfjptEvnl/uu2q9u+0E7zdStbucqTznfPWtVXbv62ZiLY9gX5MoMOFF1acoM8+je37StJm1h35RCYG5GoPJ1atuKS4P1LEArphWeq5eWV/mktxDol54+f0m2BZ8W6tgpBOp6FPKQOqR5iS3p8li/9LmZaZiKeyUBLjd7UMoRUTQV38TG4duM7c4P7UKgq09hhiZCoIpXB1PD47U7eW9cCBz6spB33323VQS0YuDoLwtpWxosM4OUyOIujnqZQnCxqm5SopeFuAterwtp7uK5ScD8RTacKRE/T8Tbk72I28bVdXOYDCiqMpVP5QbEP//Gltftl5I9pf3yD6IWe5I4tdZF26RvTuz35iY0yTPpgPS5LbFue3hw4tMoH8Wo9q37LmyrNL4T9HZp//TvHKNBmKqz/1c8GpAlx5VIWLqxfvGGebRctr9AReUb2p7xeVx/97uJY3h+ZgDj0qsZgTGzclxxHucpTCb/ahfrkb75Uma3hbNWLA/+H+blcuADqF3ZmnVZRm1nVagBXIe/cnXLt4027nrErc1X1bF4wF8STp34vlyaO69G7alHGXFsdbtzx7ra7Er8tNjp4qPiJXUYaoc9L+oXg35E8s1sXTrNjEqT+Ceuv0ob+9b/Vmxo+9z3pt6hDWXW1ol9Z120ffLHl55NrGKl83Lfpb/u9EfFQlu7TI6l/giuny59JAa6ukT7AttUXGS/ql82lpF/smkkr8LWtfFguX/4CIXsn07xck73W1+rxsijikvh+jWOEKgEXOcfH4NmBqXuz3V87PfyNS+Ng88nvF8s9EGFmMfXAN8+2/+EC5jMxT/hp7JzSNtJ8ijUKyjf3/ek1145twc/Lr81rtXKz6W+w/u46RO9+KbvXeQaLyys4L9M/50vV8qwPvIsNvec8e+K6+xYSnMs/h64XUMIXLgZf83SXzeD8E39spD0GYFpe1L2tt3vB8ypc+x+K6CJ+DeZEBiJUU48HCiCKcFRXtBhZ/w1swujMlrqXBQCnZjYvOSkea5gIwTGwqCfTaftaPybiobNMcm7sV8fG/7d26HsrOvf4hfnU13fsFyEwNAfre2v9vf+nbNxIdC+CVhm8uW2MrvPPhOwtBQ4Ps/mKc8S7LNtC7Z7WUirEGgh8BeYZraDuoBWsLgbk2qavb2I2d/NxcyDpNP4vFQ+1Q12U0a1dGHIjcto4FYX/XrZgL5QN42ieDPW4wZKbvZ8fe+bsyv2zbuNP/QNjI+ft6nxafozqTcAACAASURBVGxj+qZeiXvRTusvZ6ssE8nk0VoXbZO+CbHfQ5+1xj43Uyoby46lAnFdtBjd4+Yw8YVafiq+7NxWA6nb6oHt7rvM5qtEveR4NBvLD+LkRQ6Ff9cXfrn0ciWhRserYlr5qK5npl02Il3E4L0z4/451202iMm5OXG/G85zPm8Yb9pabU+WC3nGXeOv0kBExI3SsyZby+mqi7Wt1V9xPxoNPHTdonwan/SMm84r+70akAmnyXMqK9+7m/HVxOb2Nl/lH/jU90NNXeP+KcNPtm6am4jRUp/eaofu57Tduo/LxFb3P7WdsT1NW+ju83W9ct8VG64+lX3uuy9HrjtNG26YDfxu7V0j9n3qEvBx68TPgpe+Q/VFOi/3XdLUPs35ItwXlBVdm8Qncu8R+8Gdq8qs06t97f2YiovYrOrn+pyovVtbghjJeW3b+Noj15zgnKjd59IE+WgRUHw6Rh42r/z1aywhMIyJbQs2DtJmdZvW8dFppL5d27hN63vf9Fh9z3dJ8vXlC392VYdlruEwk0csBPXipyOfXnmIzfltfN9S3+cEnPXgR14Ot1yawddq1bbKfUfki/jepfJFEwN1LdLtPmhbsU+iMuy1J46b/hNEjZ+C+5D42hTlUfdH9bUtcx1ttVPZvY4QGL0R2L5R2IqB+s3CyVuD7dLgwstC2lYABf6J66bEPydcBc/hU3WNz5PfSqDTwleTVyVEfT8UqbxwNUwMFNFNBED7OxTSpCy1zFlETrFXnodXqKezu14u/QXz+UtPmKPA9rAMW35oh5+Zly5RDuvvYlIJcZI2rEuH76NzvxrXpxI1Je96W/ujZGcjDCIEdsRAMdXaxnY83caFQCvU/eIXvyiKgXYGYNdSYC0E/vznPx8kAtry2wL6gQ98wNhPWxqO0XjmwsDx9UdmtRld+xlD749V3qy2n/7o5LQSN8aY4dZZVnKx1APOXfF/NTPj7uk8rhFqkDfc/9P5PBaLnG3OVhEepit7Oj/MLPZJe9pFn2Kz5jV3/eolBMLCPPrjKeOw1Wv1GO3UC4GBmDilv/Ypbxf7VVZujBE38tB99D59RwiEbcvzVoTAV155pSgEapGvz3ebV59ZgDpNW0NGCKRhtPExv2PVLIK5CBNbvfmqBuoPbpjjrdqxK21IZqBs6wZz94RAP1AfZ2nwKH3JLIXAauZHNFPEz9RoZvyNUv8NtvPZxX6Ddd+1WO2mvfnrF0LgrlxPp7Rz29fqMeqGELhav+T7he38WTtG3MljtbhP7zeEwOl9PNfYa7u2IgRaUe7HP/7x2mKgzUMLfH2/awfE3xECaRgxE/P/bW8SD3sWnAzSlwii/WZGrLHMcbz2sEtCYDVIX86snSkhsLQkql5iFy2hGi+OuWtGtLzPLdPaVRFwprFXQuC8Yp/jgX1t7a3t+jUPITDXntUjVFZZuq34bfPNwR+bxbW6vf32638QAldh2fYNg5eD07b63QcfuJ8QAtv7tVXa6y6eszUh0Ip2dllvn1l/uTSrLAkWobAtUAiBNIw2PjgGHzAAAzAAAzAAA5tgYB5CILHeRKwpA85gAAY2xQBCIKxZ1rYqBFphbpWZgavOBBwiBIogyNY/MxE/4AcYgAEYgAEYgAEY2BwDVgh8/PHH3bOr8fvm/I6v8TUMwMA+MyBC4D7Xkbp1t+GtC4FWnLPP+eszO9CmWeWZgCIAyrZNbQeabmjwET6CARiAARiAARiAgWkZQAic1r/wi39hAAYOkQGEQLi33M9CCBSB7mtf+5r53ve+Z376058GH7vPHpN0627bhECOMVUWBmAABmAABmAABmBg2wywNBgGt80g5cMgDMAADOwnA7MSAtcV+PqeD8z7CTNxJa4wAAMwAAMwAAP7wgBCICzvC8vUA5ZhAAZgYF4MIAQe+FuDaJDzapDEg3jAAAzAAAzAAAxYBhAC4YC+AAZgAAZgAAamYAAhECGQ16zDAAzAAAzAAAzAAAzMjAGEQAZ/Uwz+yBOuYAAGYAAGEAJndtNHo9ytRnl8/ZF5dP14fwdPr94xy7un+1s/2j+xhQEYgAEYmCkDCIG7dU/IPTzxggEYgAEY2BUGEAI3cvN3ZM7uXZj7144G3GyfmPOLC3NRfYadO/cG6Ot2fmWAnZfOzH3lj0HnThRjKwIul3fMaWv+q8S+v19ObllGzs1Jqw3980s7rmNz48Fyv8XOyXy3jt85N2URn+ATGICBw2IAIfCw4k37Jt4wAAMwAAObYgAhcCMiwDpi0DrnzrUhrSAE1nFa59yFWThB8b45u7Smb168YR4tH5kbL3blM238phcCF2bh6ro0d17tqivHN9VxUw6swQAMwMD+M4AQuP8xph0TYxiAARiAgW0wgBBYC0xTAriOGLTOuVPWaZ281xHz1jl3PCHw9O6y55LZ/Yifm/344IY53kh7WYctzt3GhYQy4Q4GYAAGxmcAIXB8n8IpPoUBGIABGICBhUEIjISNo2v3zcWtM7eU1y7LPb/ihaeLCz2LzIs7smw3PFY1rGgpq00bL+/1s7lk+W9peec2hSRf9vk1WZZ7bk6unPvlyvfOzFHtO/FRS13kvOLy3sinQf66s1pRCMzEQ+IXxqVHXRan5k7bbMBMWWEZC1OOfeWHWyfhMnLnv4ZBx2ntyxI7cTmrMiizAvvMgNSx4jsXGRiAARiAARhYlQGEQNhZlR3Ogx0YgAEYgIE2BhACazHLgyICi30GnRdrrPiixbiMUBOJNH75qRURBT59vt/n8lZily83J+ik57YFVB+TuojgVW9VuTp9+r2qq3sGXSWQ2XOD5bV+vxa6krrE/lnEYl7q09g/jW3xueLjntvA9vicHnWxvNgXaJSeDViJgGvF3vkrZMH5IxYHrS2ZtOKrsg+HMmjT+2cFsjw4ZobfwhtbWIABGICBcRlACBzXn/CJP2EABmAABmDAM4AQmBMCK6FMiy/2uxO7skJSKNY5ISwQbcLjCyeENbO7PIwlgSs+d5ONV5et7bPfK/uzQpRO6wVVLRT6+iuh1Pk0FL7Kz/IL8x7ckLPxq3zaoy62vLZlsuPEPq6j8nfEa1EIbKunyyOXZ1yuZo2XhgxmLY4Vv8NZrvgDf8AADMBAKwMIgfo+hO/ch8AADMAADMDAWAwgBEY3oU7IaRMCs2JRNXuwEv+0gOgDpQU1eU6dLKMNt81MMoE8Ojeytw0EPzMvzN/NChw4I9CLeFokakQk7a/GFm2z/i510nnJrLaMnSI2BnWOzg2OSf4t2xaBrLsuPt82IXCs2DtbREy2zJViVuCxKBCKv5wfcj5XAq2kdVuEwIbvFr4Cn5EOn8EADMAADKzOAELg6r6DO3wHAzAAAzAAA2UGEAKjgbsWg7SoM2RGoD7PwxeLYY2Q1g1nfG45mN15DT1Xl60FOGV/VojSaXUeUr4+LsJoNCMwiktTt+jcYjopK9q2CIF58SxTXsvS4NFi7+z0PrF5pgJxVa+s/8Wn8axT7Qtbr7bjOq39ztLghsHYN/zGNzAAAzAAA+MzgBA4vk/hFJ/CAAzAAAzAAC8LSZZkdAqBCy9sXchsrcXCuHPcc/SqRhWIM1X66GUhTjAqzfIKxK2ckLapxqvL1oKYFpH8fr30N66b9qksC7YzExtxK/VpuXFqOzJ+qGe6lYTF1N6mrPRYXBef1r4sZGmyz8sbMfZeALQ2leoisylzxyuftjCWr1vGp5bHF2+YR20vSAmYLeRBmqS/adjDZ/gCBmAABmAgZAAhMPQHfOAPGIABGIABGBiHAWYERuKEFq2cUKKW+zZilxeM6pdvZIQad271Vld7nv3dnO+Dp9P4vJSg4wSlzNJNJUBO3wj6CIEy+0zZmohPlShV+eP8iv/dCIHWH2GaeAmzF1tVGcq3gR86hUARz5q8grjU51fHk7r42J3eXZrl3dOssKPjulLshcmKgcA+dyzjK+ePeIZfmi7OS9uaMCh2dDwXMfC/Oof943TS+BE/wgAMwMBhMoAQeJhxp70TdxiAARiAgakZQAhEuMiKWVODt/P5uxlyhVmB+8YUswFpI/vGNPWBaRiAgR1gACGQgeDO3y/vQDvDx7QzGICBQ2QAIZALFIOBFRlwLw1Z3jGnK56/Gx0OLwnZjThxASdOMAADMLBvDCAEwvS+MU19YBoGYAAG5sEAQuBeizjzgGyfG7sVAx9dP95fMdW+GKWwBHqf40rd6DtgAAZgAAa2zQBCIAxum0HKh0EYgAEY2E8GEAIRAvdXxCK2xBYGYAAGYAAGYGBHGUAI3M/BF4Nq4goDMAADMLBtBhACd/TmcNvgUD6dFwzAAAzAAAzAAAxMxwBC4HS+hVt8CwMwAAMwcMgMIAQiBDJTAAZgAAZgAAZgAAZgYGYMIAQySD3kQSp1h38YgAEYmI4BhMCZ3fQB+3Sw41t8CwMwAAMwAAMwsCsMIATC6q6wip2wCgMwAAO7xQBCIEIgMwBgAAZgAAZgAAZgAAZmxgBC4G4NqhgEEy8YgAEYgIFdYWBlIfCTn/yk+fjHP24ef/xx8/zzz+/UZ1eCg510JDAAAzAAAzAAAzBwmAwgBB5m3GnvxB0GYAAGYGBqBnoJgU8//bT51Kc+5T5PPfWUefLJJw1CIHBODSf5wxgMwAAMwAAMwMChMoAQCPuHyj71hn0YgAEYmJYBhMCZLQMB+GmBx7/4FwZgAAZgAAZgYBcYQAiE013gFBvhFAZgAAZ2jwGEQIRAngkEAzAAAzAAAzAAAzAwMwYQAndvYMVgmJjBAAzAAAzsAgMIgTO76dsFaLCRzg0GYAAGYAAGYAAGpmUAIXBa/8Iv/oUBGIABGDhUBtYWAj/ykY/s1ItC7ItNDjXY1JuODgZgAAZgAAZgAAZ2gwGEwN2IE+2JOMEADMAADOwaAysJgfaFIfKyEIRAoN816LEXZmEABmAABmAABubOAEIgjM6dUeyDURiAARjYTQYGC4H27cEiBH7iE58wH/3oR5kRyPJiZlnCAAzAAAzAAAzAAAyMyABC4G4OrhgUEzcYgAEYgIG5M9BbCHz66aeNFQG1EPjEE08gBI54wzd3WLCPDg0GYAAGYAAGYAAGNsMAQuBm/AzP+BkGYAAGYODQGFhZCHzyySeNFQI/9rGPmccff9x88IMfNO9///vNe9/7XvPYY4+Z3/7t364/v/Vbv2X44AMYgAEYgAEYgAEYgAEYgAEYgAEYgAEYgAEY2B4DawmB9jmBsjxYxMDf+Z3fMR/4wAecKGiFQfm8733vM3zwAQzAAAzAAAzAAAzAAAzAAAzAAAzAAAzAAAxsh4GVhMB4efDHP/5xt0TYioEf/vCH3edDH/qQ4YMPYAAGYAAGYAAGYAAGYAAGYAAGYAAGYAAGYGAeDKwlBNrlwXZWoF0ibGcGWkHQLhW2LxDRH/tmYT74AAZgAAZgAAZgAAZgAAZgAAZgAAZgAAZgAAa2x8AgIVC/MERmBWoxUARBKwrKx4qDfPABDMAADMAADMAADMAADMAADMAADMAADMAADGyXgcFCoBYDn3rqKWM/VgwUQdDOEOz7scIhH3wAAzAAAzAAAzAAAzAAAzAAAzAAAzAAAzAAA9MzsJIQqMVAmRkooqAWBkUgZOuFUvyAH2AABmAABmAABmAABmAABmAABmAABmAABrbFwMpCoBUDuwRBLQ7y3c+exA/4AQZgAAZgAAZgAAZgAAZgAAZgAAZgAAZgYBsMrC0E5gRBO0uQDz6AARiAARiAARiAARiAARiAARiAARiAARiAgfkwMJoQKIJgPEuQYM8n2MSCWMAADMAADMAADMAADMAADMAADMAADMDA4TIwiRCoRUG++yXU+AE/wAAMwAAMwAAMwAAMwAAMwAAMwAAMwAAMbJMBhMDqWYfbDAJl0wnAAAzAAAzAAAzAAAzAAAzAAAzAAAzAAAxMzQBCIEKge+nL1KCRP50ZDMAADMAADMAADMAADMAADMAADMAADGyXgVGEwMViYfjgAxiAARiAARiAARiAARiAARiAARiAARiAARiYLwMIgYiYiLgwAAMwAAMwAAMwAAMwAAMwAAMwAAMwAAMHwABC4AEEGSV+vko8sSE2MAADMAADMAADMAADMAADMAADMAADm2IAIRAhEMUfBmAABmAABmAABmAABmAABmAABmAABmDgABhACDyAIG9KVaYc/sGAARiAARiAARiAARiAARiAARiAARiAgfkygBCIEIjiDwMwAAMwAAMwAAMwAAMwAAMwAAMwAAMwcAAMIAQeQJBR4uerxBMbYgMDMAADMAADMAADMAADMAADMAADMLApBhACEQJR/GEABmAABmAABmAABmAABmAABmAABmAABg6AAYTAAwjyplRlyuEfDBiAARiAARiAARiAARiAARiAARiAARiYLwMIgQiBKP4wAAMwAAMwAAMwAAMwAAMwAAMwAAMwAAMHwABC4AEEGSV+vko8sSE2MAADMAADMAADMAADMAADMAADMAADm2IAIRAhEMUfBmAABmAABmAABmBgZgy88MIL5rHHHiMuM4vLpgZplIMgAAMwAAMwMBUDCIHcXHCDCQMwAAMwAAMwAAMwMDMGEAIZAE41ACRf2IIBGICBw2YAIXBmN300yMNukMSf+MMADMAADMAADFgGEALhgL4ABmAABmAABqZgACEQIZAZADAAAzAAAzAAAzAAAzNjACGQwd8Ugz/yhCsYgAEYgIHJhcA//dM/NY8ePTI/+9nP3OfatWuj32heuXKlzt+WY38DN3DDwBAGjs2NB4/MjReHnENaGIMBGNgMA8fXH5lH14+ja/upubO8Y05bxJv8eZuxGTbw87oMIATC0LoMcT4MwQAMwAAM5BjYiBD4k5/8xFhBMGeAFQZFJLSCoU4Xi4iSriT2Pffcc8aWhRA4L9iPrt03F/fOzFHLYC3Hxvb2HZmzexcT21yVcXHfnF3qipdPe//aUbYNre8nKwIuzfLuaZT/iTm/uDAX1We68p8xl9+5aW4/rD7vvGyeHcxKjzwuv9aU8fCmuXo59nuPPBYL8+zrb7h83nr9mchfcX78Xp/N4T5cpb85udVwvlt91XD/bCMm65ZpxbxlQfBzxx7cMMfFPsOKhUtz59XD8NW6vub8eXGCEDiveNA+iAcMwAAMwMC+MLBVIdAKfT/+8Y/NZz7zGTegtqKgFfKsoFdysD2nJCzOSwj0Isr5lW03lu3bscrAvBT/tfdfOjP3O8W3DQiB1o57Z+bs1oXpFtimFQK7B9LTlv/S2zfN7bdlpk8lxtW/+7WfzjyOXjZvPXzDXD6q8nOioPq9WJjOPBbetrdef9lcfXjTIAT2i83abbYo8OTLX6e/WefcTddz2vK2f92o6/fiDfNo2TZbufRHhuLj1Ttm2ZqHSjuQt9pOzivet+Gj1flCCFzdd3CH72AABmAABmCgzMBWhcA4MH2EvFu3bhn7ic+1v/ucnztvmn1zGUht345ZDa57CYHlBjMWK9YnTgC8ct5j5uGUQlyf2TITlh8LdHYwnRHpWv3eI49Q5LPxjQTHHnnYmYB+FuExQuCMRY91+pt1zm1ldMb+ytu9/euG2HV6NzdbOeqjO8XChemVz87FKfID9mfvDYWlXdwiBML4LnKLzXALAzAAA/NnYKeEQFkqXFr6O54Q6AdBsiTy4uLcnNQ32F4UOb/it5KmmdUVn6uWnN062eBNal87wnpcJLPlbD52+apOl1nOagUttYxUL6+TwfWJXSIsaVbwhctHzr+IZ9KJnWG96xmZTgBUsSjk075EsCrjWlXXe2emrtOg+ghDC7MoCZMZexvGfMcS2HpxYeq6Lqr8r9nZj7bO5+ZE4hMv0bYzZVqX1dmyfH5x+baDtzbY/To2uXSli4FbZhssBW6W56ZLd/MdanceXrgL8pNlwlXZ3XnosicUAkUYlnhJ/Or+pyv29ri0hfY2OwY/cR5DYu+YuXXml+E7fqXthv2LZsv2H2kZup5VG485D/yp24qO68JzHJ8b+T7Psvhc6uDtaNrknOOmr2+h/XV/bTmM+rgw9joP6dfsPp1flKbqV3QZsb8WC/tHRdtsQImfnxWYPkNQji/Mws0KbH+eYD62Ko9eLJAeP47HAELgeL6ES3wJAzAAAzAAAw0DsxICu5YG2+N///d/Xy8ljgM5jhDoBy56sOkHojKIaQad9aDFDTLDwasfjJcHnLHt8e948FsPlgYPUn19aluDgUxVFz3AS+rSDOTEJ842bUdyTgOYrVddFymnErnyNoXnil/CGNg0cZzEziYO6TkyQG3SSP7xNqmj81tVhq27CHW2Tq7+wkfe/iB/d66k9zEQ37p0iX8yaa6cK+FPfBzm6QXs2Oaw7v1myWTKrziqxQDhwdnelFEfV8KrY7liwQlwsgzYzcqzz+6TJbj9nsHXnYcV7pplwG52oBUAnRj4mnlJnvvX246JhUDrK/GniCXSdqzfW2PftA3rZ+Eq4bk1j6pfcH+AlPlJ8gz6Fi8S1/2Wjn9VF98+fR/pObHchKz5NMJ1Uzepl4jUWqRK7Ir7p6R9NW02OTeqU9COg2M9+p9Wnzd1mzpuztc1X3HfIb7w9Sn10Z15VD62dZE83DmK4/h31rcDxDv3iIPkOadSH7vtKyrqc/iejUvAPj6a0kcIgfA1JV/kDV8wAAMwcLgMzEYIlNl+VuzLAdlH5OuTJpd3sC8r6uhBUThQ9ef6fTLg8fv0OdsErMWOSLTRdWkG2v785rcXIppZkjl/hPVNB9fd5wQxKcxIC/PN1dPua0Qpl2e2zqG9Nl2YtxxXZeh83HctVkj6/NblrQbEcVnxcRE7ghjEAzFtT+AvZXM9U0zs6jGLxpVTjlcsCIhAG7YFKS/diojntg+9KCfLdoMZfHF91e/uPEQIjAQ8KwTqGYFvH1cvAumyI8pH2RJym9a383iu/7H7lHCT5BHE3pbpYx7wkstX2x3koeNd5sdxGrcvnWfHd829FoXsd2+7tqPxpT7Pz6gN215wXM1a1X7T5en98bn6WPt37Sex1e6L+h/tk8Dnm4pbzqaS7Y2IF9a9Rx6ubuH5sW9dDILZ9uK3Ztv9/NIhafs8BqHJL6wz+/HHdhhACNyO3+Edv8MADMAADOw7A7MQAkUELD37zwahazagTTOGEBgPVjwAekCqv0sDye3LDa4kfffW2aFn0cj3NkFADzLr7y12FMSBcJDccr4ro+t4TlTL+avNJ4UyAvtzaTL7ksF3vtw8Byo/nY/7HooR5Y4jU/egHtVMKiUU5oVAb0s440pEB12GsnkqITCwNfSnH+xnlmRX53gBUL8sxJ7vhbZBQqB947DM6HNc6jz899tqVqCNjytbC4Gteeh6bUEIDASTtthbO3XMtd36e1seffmR2WQS37ANdMVetzHd59jvXggs1EO3F/296vN0vtJ2wnZS2ZvhNjxX+6vre87WeF+bz23+cfpcmW159IhbJdDl/BGK9y229MlD94/1tSitT8BI5tqGEJj6rHxtIe0++gYhEK73kWvqBNcwAAMwsH0Gti4EinjXJgJKmtJsQQFJ0pWeISjpWreZgWU4QNODLQlgbtCU2yfpN7ltsSM7WIvr13K+G+DF6dO6pYPr7nPCGOXTh/lm7MzVL7cvM1AN85Y6qTJ0Pu57KIKE9sv5sjRZhJNwKwNxLYr4fOL6+996OWT4rEGdXtmcCIF9H6Cv81N1qWZbBXZkfFn0hU2be0mH2yez8sLysnn1yCN9WYh/S3D95t8eeTRlb1YIDFnsir31l455zn9deeh467zsdxGb03wdtxkxp/FbeI6ul2befu89IzDTX+t8bdlNfmH5Obvic3Np8vu0n6pydB+RW+IdHLfnZPII2tMYcWuPYVO3Nlt65JHUrcv3mbrZurM0OLtCoolTl185vuu+QgiE4V1nGPthGAZgAAbmycBWhcDPfOYz7pl/bc/9s+BYYe8nP/mJm/HXBtIoQmA1GNPL6sIBrh4k+6C6wWMwY8fuLwxsgoHdJqBosyM9ltalbUCo618WCNLBdepDF1c3eLTiWCqqJXZVaUU8yw2iw7iJr319dHxzTKU22/OVL/RA130Pbfb2pg/Yz+cbzQIMxI0qRup5b2JHUwdJIzHQ/lU2O/slTeWPXgNtnZ/40W+djzMzq3I+ze+rXg5SzcyTZcHh7D5flhPzHt40tXhXt6UeeVQvB6lnGbrfzXMD63J72CEzFlM7Kt+4N5gue7yEJfSl808Qe3s85jX+Hce+OadpG3E5XXnoeHfwU8cgN/M3Ljf8rduC5sh+F7Z9O1Jtq6Pd1+1OC5LOpxH3ym7NpbZJ75fvzs6gLUqdtJ/8Ppe2tqPL5/acNA8p12+78ugXt9AusT/eVlwV2nZnHrp/LPg6rFvUB9bn9F3O2+MxB736utgP/I7jxO/NMoEQuFl/wzf+hgEYgAEYOBQGtioE2hl+P/vZz5KPFgZF3OuaDWgDJmnXmhFoByDVYLNePlUP5mzDkIG3ms0VHFeNJ86nMKiaHLZWO/zgsq5rIsJ1DU59fesBeGYJczq41gPWnL/UwL8eEFYDRclfPYTe+y+uRyrC1X52wkATPxEdZCDe+ELSiD3KF3qg675LmsgfUcztALopT9U9EoDcQLuqq02fnBfV4fyKtU3EDu1fZXNOCHQP0F+aO68qW8TnURm1X1SdnJ3qd+1jyaPXtnlT8O1keW5jV1kItGl65FGJga6MaJmwt7sjj+D8m8bnEy9JtrZ4UWK5LPi1zScZnyeCXpQmjL0tX8e88V8Qm9Y8+vGjGfVshG0gKC9TZ90vaI5i1uNyWv1h+2Jbt7hPjupr7W3y8f6q+a77mLQ+YkvahjN5xO0ismFbcbNxkXo0dU7rmlwHo/q05qH7x0zsh1xHe73QyInv7W8X7pVP1tZCGyItsxU3wABCIO2v61rKcRiBARiAARhYhYGtCoGrGNx2zmhCpxYlVQAAIABJREFUYOvNnR4kA11bPDZ7rIf40RrXw42lew7X8o45xT+jDWy9T9uFiWz7cGJRRpQhNqPFJuv3tf1L/zONXxdmUc2wzf5Z4eLGbMDJfL92uzjc6+pYMUEIhKGxWCIfWIIBGIABGNAMIAQOvtFFCNQAzec7A/HVY1HNYLt7OnOxZVc6b7+ccfnghjke2r8gBO4og/Q/q/c/3e267c+K7heK9F1e3G3HlHUkb/yfYwAhEC5yXLAPLmAABmAABtZlYCNC4KNHj+rlv32W+A6tlF0KrJcYr700uHXwjhA4ND6bSc9AfD0/WzFwhRlsrW3l8DpoL1gszXJVURUhECGQNpVlwLatR9ePo2NW5GufzZw/7/D6pvWuD/hrW/5DCIS9bbFHubAHAzAAA/vNwORCIADtN0DEl/jCAAzAAAzAAAzAwPgMIASO71M4xacwAAMwAAMwsDAIgcy+iGZY0DHQMcAADMAADMAADMDAthlACITBbTNI+TAIAzAAA/vJAEIgQiBCIAzAAAzAAAzAAAzAwMwYQAjcz8EXg2riCgMwAAMwsG0GEAJndtO3bSAon04JBmAABmAABmAABrbPAELg9mNAOyAGMAADMAAD+8gAQiBCIDMAYAAGYAAGYAAGYAAGZsYAQiCDz30cfFInuIYBGICB7TOAEDizmz4axfYbBTEgBjAAAzAAAzAAA9tmACEQBrfNIOXDIAzAAAzsJwMIgQiBzACAARiAARiAARiAARiYGQMIgfs5+GJQTVxhAAZgAAa2zQBC4Mxu+rYNBOXTKcEADAxn4NjcePDI3HgR3w33HT4bx2en5s7yjjndgWv68fVH5tH1Y0S3iWO1D372QuAfd/evr94xy7unMDUxU+P0VfT5+BEGYAAGYGD7DCAETnHTcOXcXFycm5Mp8t7BPI+u3TcX987M0c7YfmTO7l1MZrPzx8WFuXCfGXMyCccn5vziwpxfGdD5XToz92t/DTx3VOZWsH1o+av4fIpzXJ7CqN/ev3ZUGGRaEXC504PQD7/yrvmDN6vPn33XvHdo3DrTf8k8+Wfvmt/9ypcKPsy1h1XOyeWT33dyy8Z12/3PM+bGgx+Y5YNvmONOH+br4W8krQi4LItrFc+D+p2iPev1A1acWpYEy8uvmdsPb5rbb+dFwpfevumP2zQPXzMvFW0s+6ozj6OXzVsuf1/WW68/kzDbmcdAu9a7Rzg2V4v+8FzcebXsj3EGIm029Ci7xef1jEAr9JW4cf72/TACcw9/D+RzHEawCz/CAAzAAAzMiwGEwCluCFYZmE9hh8tzvUHLGA12vZv8kRuME5Xum7NLbflOKwTWPp0VJxl/TGLfOjyuc26mfoPb3AbKX8XnU5wT51mJsTkhxQkbD26sKeS0xKdXm205f0Cc3/uVn5g/QAhMhJ+6zxrgy37njCMEnt7tEKIdzyP9iWDzWvWPrRdvmEfL/MxZJ669/bK5/E5eCHz29TfM7XdeNs9WMXDp1e8+/u7OwwtaVy9X7akSqOrfi4XpzmNoW/TX21zf0qdO3g9vmLdKwqgT0PI+75N/Zxon3r5mLtv4lGxobTftPq+FwMXCOM7b+lrH19JML3wOjTHpOzlqZQT/4T8YgAEYgIHxGUAInOLiGw+ipyijd54bEC86bNk9IXD8hpbtvGbFSabOk9i3Do/rnJupXwe3acw2UP4qPp/inCRPP1hPZwVuYMYNQuAGhbkx2smG82gR19I2vK5tpXbQL9+iYHn5NeNn3j1TEAIjscj2XRmRrr2+3XnEIp/NLxQcu/NotyHjp6SvyaQp9dXOB6+Zl2RbSFf0eyF9/zocm6uVGOt8t4IQ2OVzLQQuFt397eR/zKztswHxpSz6fhiAARiAARiYjAGEwCxc1YywtuWI1QwZv7wzWmIlN7ZuWy2vW3UGQda+PjdSXrRo7KvssHW6daKAiusaz5az+dh9Ol2cZmEWuq62DFVfEQJP7BJh8WlgQ5/6LIzLR86/uDChKCF2hvWuZxkk8Wr8ofPxy+VKMavKuGaXfvs61nVaoT7eZ7mleVKXDp93sZHUOVNWW5peHGsbw7jXg6mYjWBpsI9XHSdbJyk3qV8mbZ2mww5XT1t/n4fnMOOPOr8ck23lV+ljf6p24Op178ycuSWZlt8TvwRd+0PqHvgstTPg1LWJKE2bHa0+ruohdog/3O9Mu7ezbVpmqGyizdacia1rbFtnBD73o2b5sF1G/MqVqh/1S3g/+5Xvmt91y4t/ZD4saevZhbLM94pbIizLkJOlwk9LHs1S5ThNsIz5zXfNZ5/LsVreF8Yk4kb7zs2kalluq9MG3/0svzvXv2EeLX9glsvvmNNXv2OW9rtaAnx61x6rPmq/xPP4+jWzvPtl47aS7u6X1bXL19EJH6Vno0XtIOhnApvL/hJ73LbuR3qmD8qwIk7XzLSCEFjNOtNLgZ1A9/BmJSD2sKczD192sBS4EhvrmW6defSwI/DJwti+TF+DA39HacNjyt4OIXDRuax2uN2hLdVMycFCoKqD1DXyeSgEVrMCS7zbPDYqjK/vt9iP/ManMAADMAADMLAZBhAC5eZLbd0gu03YqQYXxUGFDOJrEcALCENudsPBWiNaaYGtXyNpEy8q8UTXNRnwN8KJ2O9sq+smwk1GJKh8WtdFyunyn4qF1NHnoQetsU/FzsaO9JyFWbiymzSSf7xN6uhsqsqwda/q4ETVWDTJ2B/n734Xz5O6NAOkvD1tnYTPo8iotbErDp0cp/y4ttPKRmxX/Ft40rGWembSOl/3sEPipUS3znaexLFUvth3ZM5u6Wdh+vTSbkQst789m36pYmBH4vMedUs46rDD1is5R+pQbcWOWnjPt5m2mTZp+4v8UYuyTd7pOcJpkybblpJYRfXpebwsBF4xn62Fv4VZVIKdF+G8yPcHb/7IfHhxxXzWioFWAHRpfmKefNraImmUcOfEQjke59mcEwiBz/0oEP6cva7cFerbxcCaQqATABdfNndEAHzRCoPXkhfKOKGvJATac0X8c+f/IFr22Pe5aF1tt5//grbak6ma115iVIsQWC8D9rPyrGDnxMDC8wTrcsVOK+K15uHLlmXA9Qw3J0y9YS4fLcyiM49+fqxt63k9rtNLXexW29IlBLqZdF0i7EDbtS2yZHpFIbDN57EQ6ETNlj9fFgvfJlgevF48s8xFMScNPoYBGIABGNhlBhACMxd2d7Pf8hD1zsFAZoDVeU7GjnHAahkAZW/CvfBQixfVYL35HYsIcfq0Q0hFrO5zwrrn04f55upp90UCQrbOfWy2aVQZOh/3PSdcpfkG9cpw4o/7cso+78jXseTzCGd/hud1MpmxLzgnV2/tl0VutofyobIzECwz5Wq/BGltHj3syImeIT+hb4I41W0ztr37nMBfql66bPddRHKVprbB7qvFVWtDxHTunNpmb2Nghz3WdY4+HsW0tqsacOYfTr/5NtvY1R2XUtqyEBjnKTP87Ms/9HcvBHqB0H4XoU+nkbz8PpnR58rWYmOQr5wTbQOxMToWMZDUWce4K+2g435G4KPr9iUTXgj0ooT9PlAIDARCna/UtXuppK/38Lab+Mv1/1HbG+CXfks2O4RANyOvEuWqZbvBDL42e0Q4K+YhQmBkgxbZOvOQuPTbBn1fm+3JsWiJsrYxSWtt6ctJP7tTNtabEXj1ctnnWSGQl4YkM4NzMWHf6jzjO3wHAzAAA/vPAEJg9qbRCxj1MtZ6EG6ByA9wg8aSGWAlA/FCuZKPu0GuZ+NMNCMwY6ctP7S1awDVdbxa0jvUh4F/CmUE9ufSZPYVRY2wsWuhRmKyaSEwEbwCn4T2Njbq/b7+wnEgLI7BsfO/YrPmVQbLubYSxyT+3SZSZdJan3TaIWKh2KV9NOR7oXwVl2y7zYh8mi/3PZOmjqnmPMevPl7Z0mpH7bMW8TrK0/YJIT/Wb22zsQq+CvLNpcnsy9VZ+bz20wj72oTAeEmuXd7rZ+tpkW+4ECgz/lz+nUJgNeNQ3nDstiI2DmFZ2k0LAyv7Uwt2+yMEBu10Bd+sLQTaN+PWM/psrL14NEgIbM2jEqMe3jQyQ821LSccVm8odt/XtKP2nW3rq/XJbraingm540KgfVN0yecIgQP7tZovzhvz2khe8AQDMAAD+8cAQmDnTYMXM/TMqlAoy0ARDHb98c5zOu3IlNPrnMzAWs7LDrBj8ablfJdPnD61U4sevhPpPifsbPLpw3wzdubql9sn/lDbMG+pkypD5+O+rzCgznDi663KUTaFPhGbem6djeFbMzuZzNgXnNNZ71zc4rrFv9sEikxa659OOyTNaoPOxu+F8iVGzl9hGYG/lD81X+57ixCo0/q6hmUks/u67LD2Klua+imW4uMFH5eXBudiH/8pkPGnKyeqX26f+HzkbUkIdPuDJbha/NPfhwiBOu3CdAuBvpzm2YSynPiQhcA2MVrxrGdzr8SM53mtP2fWWRq8iGbAuTrYfc3swGw7DuranUfuxRWh6NadR7cdVVxsHxP8Qajj1fa9ESytgJZ8tEBY17/P8xnbyuw+Vi+lrsvsPsf6qsvnWSGQpcHMCBzIWe92Sb6wBQMwAAMHwwBCYA/Yg8G8Te8GyaGoElxk40F0Msuu3w1ikGcPO/Pp/QBGC5lNuvSYEx2CZdGZwXpkiz8nGryrNIGQ4fbnRQJZvnkRlO99ldjlxAEdg9ROF7dkoOHTpbObwpikNtvjqgwtTrjvoRDo7Y1fzBKWURZjVDnKj03conx6pcnkuTbHKT+xjaEfvQ12hmIzoI5YqOKaYyDwf1DnbjuyAlqQR+XTlcr35yaMVv6t257qF7Rf3PeiEOh91vAa+UvKUG2m0w5bb2VLHDP3OzkelSu+axE3Ejsq3zaxT5lcuc26B+QvW19ckq2n1KPaloRAJ9LVL/5YGC8MrjcjMBEX3TMD7XMGLU+V6FfPOrT7vHAoMwibNBMJgWs+I3AzS4MXpt9Mu5S1PjzUaWx7SK4lVZ8RMVSfk+zvszw1WiKq8vAvB6lm5iVv8+1nS2cebmadegFJ9VvPVuvMQ9lc9oXvT5q+oJ/9xfy6ZgS29FP+5Rrr9x1dQqD3m/Kt+KnD57EQWP7zpfIhLws5mAFcsT0IW2xhAQZgAAZgoIUBhMDEOZWoUC9z7PsmVCUEJYPoeLntmje9ic0d+dXiRrWMU0QHl08jzuTfpNpvAOUH/WqZqBo0uWPqd3F5dW2n8qWqqxMJVFzCQURcjxYRzsWnsbURWTJ5uPLEHuULZ2slfrrvksbHovZH4Gt7LMOXK0MLqaocVf9BN321L3P1VLxEvggEuF4cZ+qTibUsTz6/khkABjacm5PIn7UvVextfk3cCn7Vduh4tfm09lsYT+/7PB+NHZEv7p0Z91ZpYUD5U7cJ913S1OU3cQs5l9mNcjz1V8JYbIetf+BzyUsxqGytuXP7VBrnx3ZxY/o2Kyz7mWHL5TJ6mYQcb9vmltvat/aKKGfPjdK8csXN4Ou/NLia8aeX9CphUXyslx/bvO3vRvhbmIW8jbjK57PPWbuGCIERo3WbiuO6MP5Nq6u/NbhdCKxeIiJvA6633zGnVftMXyKilxyreLYIH/36DpVXoW+wHDftvDu9xDPeFkWcSgxKZrcFS4EX/uUgMgsuOhaXVfotgpQrK5dHZIsWASXPzjwKfpTze83i7spDH+8QAot+d3ms03eUZiemMzXFZ9ml3C0+D4XA9v7W+refML46w3UMtf/5zkATBmAABmAABnaOAYRAoN05aPM3oiOIZ7CwJywwyMm3kWn84gaerQ+vL5U7bpv1dkz7ZtBN+pWyStyk+53Q07pcMj2nt3+jPyZ6n5e7nlQzVw/9ja5jCau9YtE2G7CK0Zz7Di0EtguaC+NnN9IH9uIi1z7Zxz0gDMAADMDAATGAEHhAwd7vm6NxRYX99tUag2LaCxfIhIFqRs3d04G+GbPN+pkyy6nEoKTOtKF59ZE+/vk3WK8XKzerVWbsjsDB6sL5evWYTbz6zs4ewdf93hY8776jFgI7Bc2+z8vcE45G4QNfzKZfIJ4D759gF3ZhAAbWZwAhkIvPnlx8xhQV1m9Y03VOvp6y1Da3TZaSwvieMD5nLu0gdOhMlHHarBdWlmY5WIicsz+xbXgfagWdO/XS4uHnb87nltkxRcvSEuj6+qAfk3BA14MuP+9C3+GFwD/u7l+tUEgfyLX+gNr3nPt4bNvc9RRf42sYWJ0BhEAumtw4wQAMwAAMwAAMwAAMzIyBekbgzOxi4LX6wAvf4TsYgAEYgIE5MIAQyM0VN/4wAAMwAAMwAAMwAAMzYwAhkMHiHAaL2ACHMAADMLB/DCAEzuymj0a2f42MmBJTGIABGIABGICBoQwgBMLMUGZIDzMwAAMwAAN9GEAIRAhkBgAMwAAMwAAMwAAMwMDMGEAIZDDXZzBHGjiBARiAARgYygBC4Mxu+oYGkPQ0ehiAARiAARiAARjYPwYQAvcvprRTYgoDMAADMDAHBhACEQKZAQADMAADMAADMAADMDAzBhACGSzOYbCIDXAIAzAAA/vHAELgzG76aGT718iIKTGFARiAARiAARgYygBCIMwMZYb0MAMDMAADMNCHAYRAhEBmAMAADMAADMAADMAADMyMAYRABnN9BnOkgRMYgAEYgIGhDCAEzuymb2gASU+jhwEYgAEYgAEYgIH9YwAhcP9iSjslpjAAAzAAA3NgACEQIZAZADAAAzAAAzAAAzAAAzNjACGQweIcBovYAIcwAAMwsH8MIATO7KaPRrZ/jYyYElMYgAEYgAEYgIGhDCAEwsxQZkgPMzAAAzAAA30YQAhECGQGAAzAAAzAAAzAAAzAwMwYQAhkMNdnMEcaOIEBGIABGBjKAELgzG76hgaQ9DR6GIABGIABGIABGNg/BhAC9y+mtFNiCgMwAAMwMAcGEAIRApkBAAMwAAMwAAMwAAMwMDMGEAIZLM5hsIgNcAgDMAAD+8fAKELg008/bfjgAxiAARiAARiAARiAARiAARiAARiAARiAARiYLwMIgYiYiLgwAAMwAAMwAAMwAAMwAAMwAAMwAAMwAAMHwABC4AEEGSV+vko8sSE2MAADMAADMAADMAADMAADMAADMAADm2IAIRAhEMUfBmAABmAABmAABmAABmAABmAABmAABmDgABhACDyAIG9KVaYc/sGAARiAARiAARiAARiAARiAARiAARiAgfkygBCIEIjiDwMwAAMwAAMwAAMwAAMwAAMwAAMwAAMwcAAMIAQeQJBR4uerxBMbYgMDMAADMAADMAADMAADMAADMAADMLApBhACEQJR/GEABmAABmAABmAABmAABmAABmAABmAABg6AAYTAAwjyplRlyuEfDBiAARiAARiAARiAARiAARiAARiAARiYLwMIgQiBKP4wAAMwAAMwAAMwAAMwAAMwAAMwAAMwAAMHwABC4AEEGSV+vko8sSE2MAADMAADMAADMAADMAADMAADMAADm2IAIRAhEMUfBmAABmAABmAABmAABmAABmAABmAABmDgABhACDyAIG9KVaYc/sGAARiAARiAARiAARiAARiAARiAARiAgfkyMIoQuFgsDB98AAMwAAMwAAMwAAMwAAMwAAMwAAMwAAMwAAPzZQAhEBETERcGYAAGYAAGYAAGYAAGYAAGYAAGYAAGYOAAGEAIPIAgo8TPV4knNsQGBmAABmAABmAABmAABmAABmAABmBgUwwgBCIEovjDAAzAAAzAAAzAAAzAAAzAAAzAAAzAAAwcAAMIgQcQ5E2pypTDPxgwAAMwAAMwAAMwAAMwAAMwAAMwAAMwMF8GEAIRAlH8YQAGYAAGYAAGYAAGYAAGYAAGYAAGYAAGDoABhMADCDJK/HyVeGJDbGAABmAABmAABmAABmAABmAABmAABjbFAEIgQiCKPwzAAAzAAAzAAAzAAAzAAAzAAAzAAAzAwAEwgBB4AEHelKpMOfyDAQMwAAMwAAMwAAMwAAMwAAMwAAMwAAPzZQAhECEQxR8GYAAGYAAGYAAGYAAGYAAGYAAGYAAGYOAAGEAIPIAgo8TPV4knNsQGBmAABmAABmAABmAABmAABmAABmBgUwwgBCIEovjDAAzAAAzAAAzAAAzMjIEXXnjBPPbYY8RlZnHZ1CCNchAEYAAGYAAGpmIAIZCbC24wYQAGYAAGYAAGYAAGZsYAQiADwKkGgOQLWzAAAzBw2AwgBM7spo8GedgNkvgTfxiAARiAARiAAcsAQiAc0BfAAAzAAAzAwBQMIAQiBDIDAAZgAAZgAAZgAAZgYGYMIAQy+Jti8EeecAUDMAADMDC5EPi5z33O/PVf/7X5m7/5G/f5yle+MvqN5nPPPVfnb8uxv4EbuGEABmAABmAABmAABnaVAYRA2N1VdrEbdmEABmBg3gxsRAi8evWqsYJgDgYrDIpIaAXDON373/9+861vfatO0yb0fexjHzO2LITAYdC99PZNc/uhfF4zL83sH/EcN+wbFmP8hb9gAAZgAAZgYLcYQAjcrXjRvogXDMAADMDArjCwVSHQin6XL182VuyzDrOioBXyrKBnf4sIqGcRWpEvJxja9AiBwxves6+/YW6/87J5thL/nCiofu8KyNg5PPb4DJ/BAAzAAAzAwHwZQAicb2xoN8QGBmAABmBglxnYqhAYOy4W8uLfNr0VD0szDHPp4zL4rRvssbn68Ka5elntO3rZvBXvY4ZgdjYrLCluYARGYAAGYAAGYGBUBhACuc/gXhMGYAAGYAAGpmBg1kKgrbAsHbYzAWWG4CuvvJK90RpPCDwyZ/cuzMVF8zm/EgJ4cqs5dnFxbk7im99LZ+a+Ov/+tSNls8///EpYTlzGFAEP8rz8mrn9MFwKLMuE33r9GWVvWPcgj7je/MZvMAADMAADMAADMLA2AwiB3H9yzw0DMAADMAADUzAwKyEwXhosFbazAOWFI3qZsByX7VhCoBP5bp0Ub+Dc8Xtn5qi6yT26dt8EYmAlAjbC3ok5v7gwjRjYCICSJsmj8wba56nFSvkueYpfilsrBNbLgP3sQCsAOjHw7eNi/Yv5ddpMI8Z3MAADMAADMAADMNCHAYRAOOnDCWngBAZgAAZgYCgDsxECReyLhT47E1BeECJp7MtD5LmCusKjCoG5WX5O6LIC3H1zdknD5kU5EeCcqBcJiW5fLR56IbARBhdm4cTDOF9dxgTfRQh0MwPfMJePfBlWCGRG4AT+RihFXIYBGIABGIABGOjJAEIg92J6nMN3eIABGIABGBiLgVkIgSLwxUt+RdjT4qCkzb0ZWNLnjg11WLD0txbwRLDTy4Kb7yIEBueq5cEXdT5jCIEjzQi0bwuuZwXahvWMufwOQuBQXkhPpwwDMAADMAADMDAmAwiB8DQmT+QFTzAAAzAAA8LA1oVAEe9iEdAamBP9JH1O7Gs7JhUevq2W8dYz/HIzAkOgcjMCw3LHEALDMsP8+x7LvCxkYfc1swNXy7dv+aTDvzAAAzAAAzAAAzCQYwAhEC5yXLAPLmAABmAABtZlYKtCoLz8o7TUV45rkdDODrTPC7QiYVz5aYTAhYmfGRg/IzC2wy/zvTAyQzA5vpiLELjwzwNULwxxzwcMZgjSyNL44RN8AgMwAAMwAAMwMC0DCIHT+hd+8S8MwAAMwMChMrBVIdCKevb5f/FHC4Mi7kmakghoAyhpc7MF+we4mgGYXdLbNJR0+W/05uDorcH2RR7NMwHnIwRav8ibgm8ny4Sb+vb3H+fgKxiAARiAARiAARhYlwGEQBhalyHOhyEYgAEYgIEcA1sVAnMGrbNvHCEQUNaJAefCDwzAAAzAAAzAAAyszwBC4Po+hEN8CAMwAAMwAAMpAwiBPd/cBjwpPPgEn8AADMAADMAADMDANAwgBE7jV3jFrzAAAzAAA4fOwEaEQLucV5b26jcAj+V8uxRY8rfb9ZYG0yjGigv5wBIMwAAMwAAMwAAMrMYAQuBqfoM3/AYDMAADMAAD7QxMLgQSgPYA4B/8AwMwAAMwAAMwAAMwEDOAEAgTMRP8hgkYgAEYgIExGEAIZGlw8vblMcAiDzooGIABGIABGIABGFidAYTA1X0Hd/gOBmAABmAABsoMIAQiBCIEwgAMwAAMwAAMwAAMzIwBhMDyAIbBHb6BARiAARiAgdUZQAic2U0fMK8OM77DdzAAAzAAAzAAA/vCAEIgLO8Ly9QDlmEABmBgXgwgBCIEMgMABmAABmAABmAABmBgZgwgBM5r0MQglnjAAAzAAAzsCwMIgTO76dsXsKgHnSQMwAAMwAAMwAAMrM4AQuDqvoM7fAcDMAADMAADZQYQAhECmQEAAzAAAzAAAzAAAzAwMwYQAssDGAZ3+AYGYAAGYAAGVmcAIXBmN33AvDrM+A7fwQAMwAAMwAAM7AsDCIGwvC8sUw9YhgEYgIF5MYAQOFgIPDJn9y7M/WtHE/9zfmLOLy7MRfWZvrx5gblSR3H0snnr4U1zu/q89fozaYwuv1Yft+muXt6Deg9mmDqvxBd+TtsTPsEnMAADMDAZAwiB3K9wvwIDMAADMAADUzCAEDj4BnZTQqAAv+nypNxd2z5jLr/zhrl8VNldiYKB0Of2qTROFFS/B7Owaz7C3ik6UfKEKxiAARiAgSkYQAiEqym4Ik+4ggEYgAEYQAgcLP5sWpjbdHn70yheevumuf32cf1Pffx7sbDiYZiGTnF/4k8siSUMwAAMwMAuM4AQCL+7zC+2wy8MwAAMzJcBhMBECLRLcu+bs0t6aa79LUEUYe7ELRFea+nupTNzXy3/vbg4NyeJPVJefinyya1m+bC15fyK2Flte5QR55EsQ47ySI4vvI3ii6wdSb0iOyc4Hgp/x+ZqvBRYlgm/87J5doLy6fimjzE+xscwAAMwAAP7ygBCIGzvK9vUC7Zv67VgAAAePUlEQVRhAAZgYLsMIAQmApAIgI3454Sye2fmyKVtRK9adLtybi6ceDggmJW4VueR2CF5tQiBV84D4e/o2n0Tiom+Lm1luHPqukmZapvY6fPUYqDzz62Teubd4EYdCY2NoNjEYHCeydJgKwQ2y4CdSGgFQCcGvmZeKvpf+YI0q8cY3+E7GIABGIABGBjEAEIg92CD739pY4PaGP6ljcEADBwqAwiByQUzI545oU9m6+WEOb+vTXCLAesvnuXKKzRYJ6hp8awSNVtEOi8e6nPCvN3x6PxYPPQzCsU/4flxvTfzu1ryG8z0EyHQzwysXyRihcAg3Rzsx4bNcIKf8TMMwAAMwMB8GUAInG9saDfEBgZgAAZgYJcZQAgcUQjUs+TaoRgg7lXLbvN5V0JfsLw4FvXCNLl8vBgoS4xDQc+LfHJMbaNZhEG66Fi7LxZmMeqMwEoEfBjP8vMC4G01K9Da9ezrbyAEJm2ATr2TWXzGP+4wAAMwAAMTM4AQyP0I9yMwAAMwAAMwMAUDCIHJTdwqMwIz5yT5hgCvPyPQi4kXerZeMiMwLFMEt7aZi84uJeTlZgS2g5ixq8MX7flFdejIyy35TURAn0f4zMBmXz07sCPvMe0kr2FxxV/4CwZgAAZg4NAYQAiE+UNjnvrCPAzAAAxshgGEwET8yYh6HUuD/Yy6cCZdJ8Auz8zLPRJ7SrMHvZ3NDL9KgGt9VmGmblF58bLfPuJhXNf+Iue4kLvZfdGMv8C26uUgVy9X5brfzXMDg7SRXzg2bqzwJ/6EARiAARiAgXYGEALb/QM/+AcGYAAGYAAGVmMAITARfDJiWSAELkywDNYuy1Uz6AaBWImBzcsxlJiYHKuW5eoZgFGa8yvWdrU0OLPkthEOPTBJXXJvLm7NRwTI8rLhQT5J4tET7OrlILcf3jThJxL6KjHQp4mOrVo257E8DAZgAAZgAAZgYGQGEAJ73gOO7PeN3LdiM/0FDMAADMDAFhlACNyi87nR4AYPBmAABmAABmAABmAgxwBCIFzkuGAfXMAADMAADKzLAEIgQiBKPAzAAAzAAAzAAAzAwMwYQAhkoLfuQI/zYQgGYAAGYCDHAELgyDd94Rt41XJZebPvqsuIR7YzBwP76CRgAAZgAAZgAAZgYB4MIATOIw60B+IAAzAAAzCwbwwgBCKwMQMABmAABmAABmAABmBgZgwgBDLw3LeBJ/WBaRiAARiYBwMIgTO76aNhzKNhEAfiAAMwAAMwAAMwsE0GEALhb5v8UTb8wQAMwMD+MoAQiBDIDAAYgAEYgAEYgAEYgIGZMYAQuL8DMAbXxBYGYAAGYGCbDCAEzuymb5swUDadEQzAAAzAAAzAAAzMgwGEwHnEgfZAHGAABmAABvaNAYRAhEBmAMAADMAADMAADMAADMyMAYRABp77NvCkPjANAzAAA/NgACFwZjd9NIx5NAziQBxgAAZgAAZgAAa2yQBCIPxtkz/Khj8YgAEY2F8GEAIRApkBAAMwAAMwAAMwAAMwMDMGEAL3dwDG4JrYwgAMwAAMbJMBhMCZ3fRtEwbKpjOCAWHg1NxZ3jGn9A8IA4fIwKt3zPLuKbE/xNhT51lxjxAo12S23J/BAAzAAAzAwJgMIARu/ab3xJxfXJgL+dw6Gf8m9NKZuX9xYe5fOxo/7637b4UO4cq58/f5lRXO3cX6rmqz89O5OVn1/J09z4qAS/Po+vGw9rIhfx1du9/0FxeHGJ9h7db5696ZOZqUx7Af3/2+9tjceLBCG5jUx8PiPuaNEnnh+20xgBAIe9tij3JhDwZgAAb2mwGEwK0OXI7M2b0LczGF+KfrtS9CoKvHfXN2ac1GuRNCoBcWtipWbkjYmttF5vTucrXZUJv216bL033KDn3fjBAofZLv03dfCFyYxYs3zKPl0tx5VerGdm59FfbsP5MIgfsfY9oxMYYBGIABGNgGAwiBWx3QzkDs2Wr9Bzb6sYTAnajzDNg4RKHJiR+PzI0XB7Jpmdq0vzZd3k60mzRuCIGpT/rebBxff2SWD26Y4x2Nfd96km51RvDdtL5DCJzWv/CLf2EABmAABg6VAYTA0gDHDbLVkt1gaVk1k0+W815Es9TsuTa9ziM4Xxpci9iTGeSf3EpnD7p9tR3x8l+fvyw7zs9SGasuUqd4a224b86u+eW41i8nsrQxmAnZYkc1o1Hqobe6TtYX9rdeOqmPL6J8ktl2VbyCc6p9SdoSN2vvD2Om6xrOHG3xl7Oh8vslnS7i1KaLfHKhl5oKg5UPnC1ZjuOYq9/63JrT2A5t44VvO9qPzka7BFb7Jl4Sq4/ZdhsfF6Gu1Ka9zU74KDwbzXF16yTgK4hJzl85O3TdCt/b23XlXykvl0cc10zcOsuI88jUJcxjNZ+vd/EVznX8Q75ECKz7Hcthxh/ddkScXlyYtF/waYI+RMUn9Ffm/ME+j/v8tE3nbIntyKVx/lhHGFf17vat6jM4b9gjCfDXXvsLIZC+gf4TBmAABmAABqZgACEwdxPtBtjhYLJxfjUY1CJWnN791oNNP0itB1tyvBZGRJxQZbo04cDaDd5UuTLA7X72VWlwOkJdcv4L9lUDdDvwlkGurUNUv6Nr58GSX1fXeLDuzlc+CspZmHpwK+cV03ub0kG8iEVVGZW92XRR2cKHFiEDEU9sKpwn5zfbFhsXPeKmRDPhLuGlq37CaW17xHHvujSdt42R2OPrmtYliX1lp/WnxMKlqdtCapePg2o/RRYa2xaL9uei1bGVcmP/Jf5K69bEV5cbfk/qX/Jz1IaavI/M2S39TLyCf+q4huX7fNr48+ljO1fzea7sIfu8nRfqz5i8XfpPlNQfje9KZfeNpU8XMl7leeW85teWl/irarPCeM4md05b3GImqzy1PZ15BLz5NsHy4BIX7M9xyr7xuEAIHM+XcIkvYQAGYAAGYKBhACEwGPRYx7QM5GzarKAQnZMZoIfChQSgZbDdIw8/kCwLYw3okX1S51HrInWKt6qOujz3XQk1YpNsM/XP+74pLxYAFsWBtbJJylNbP1A+N+f3YtGqKavx7VT7WmzUfqztjmPsz9cCQCy+5plU9cnEoPOc2h6VT7XP+VVENEmX4yCun/vdiIDW94GYkbEziX2VR+APsaHe+peElESPoEx3TuTznB12X5twU5dd+Suue3xc/86Vp4+r73HcXF2UeJby7PkJZjyq/Lx/474nYraXz1NOUlva0kRlWhsjv6Rxq/iJWQzqF5UZ5Vm2MWKiLc8k1l0+F/Ew9ntjq6trVK+4/t2xb/LrEsfLftB58B0/wcCqDCAEws6q7HAe7MAADMAADLQxgBCYDNQyA0udpjAgDAbamTTB8Tq/lrJ65uEHdTKjsCSsFQanmTIsLIGtmTTB8boupYam6qgHvu67srcSDYJZdPFSRH1+ptz+dimbMvmIGDxIwKnyCeMhcdGzQ0t+ive32JiJSRK3oggq5RSY0P7IlNPfx1JOtY3jLeW4MpSf6lmySuzoiHssdPgOL1O/iLF05tVEQmDMsdQ9t834vNiBt6TNcpgTiGp/q7ZY2+UZlDYZiKiRLyWNnrXp7I7SpT6POKnL7rs/004iv+T4yO0r+jkWnlttzHBXpw/96X2mOHfpwjSBz6t8wtiGcXPts46paleRGN2WR+iH9lmyYdq+MSMdfoOBvgwgBMJKX1ZIByswAAMwAANDGEAIrAdpAk7bQG5eMwLjQLtBYDTg82kKdcoKLFHaaFBt8xsmBqmBui7PfZdBrE8TDHoz5faaERiJHbGP/G9lUxL/pn7D6in8jLVtsVH7sbY/ilunENjUM++jdGbV8NiLL6xtseBRHQs4kPTRNltflSbHSlf93TmxTe2iRyoeRT7P2JGeo+yuY6f2ddVVn5Mpz8UyU7culst9R2Wbs0vPyrR8xv5T9dB2yveMXUX25JzObaadRH7JxaDLH4ldUZ7J8drOiIlofzDDsivWic9T/8Zxc3Xt1Qc2ecV5hHVjaXDoj8Zv7McXm2AAIRDONsEZZcAZDMAADBweAwiB9UCtCb4bTBUHuX6gpwd0Pr2IWkMElMwgVuyJBom+DP2cq8ZeabguzRAhMPOsudXrktrj7VJ11HVy3yufJQNef076wge/PxAMxV+DBEplkzrf2hvWv7088fs025Szppz0WGi3jUW5jnU+TtzQ4k4Uw4z4kRVQqvil8fL52XNKMatnX7aJF5qbKF6+Lmmc2sWNkqC/MG1vSU3bVyT6JP5K7ap9n62H9VcV22w77o6PzT9hoYqz7rNiO9K6RWVleOr0cVzHUhzdCymWK76dNsN5FIekbkl/E9c199uX0+ZD79OIidoHMQtVnIvXGWtDpm51ft7GMeqW5KHL4GUhe/0iirgf4Heu7W93H0Lgdv1Pm8D/MAADMAAD+8oAQqAe9KjvbnCkl1gFA/NqUFgfVyKgzSMaiFp4sgJKx0DPnSNlyNtKlWASHHfpcnao5WEqrwbosepS6iTUYFYLAe57Y2/o7/vm7MqZuZ9bUimiRlUXLTDlfdzYFZbR+EXykOPB8sWqPEnT+K3Jd7J9lWBRL7tUsReRoD6W+Er5XXGd2Br5MxDz+nJc29nEsy4nyd/7PfSniCJNTIJl2ZqbUl1qG6o8gvYqbVLlr148Uttq824RPhwfQb6R6BPbUCqjVId6f+qPxl/psXSJaZRG3tSt+OnsOzJ1aWxo2G/NJxP7oG3V9fWzzpbLpSk9nzGIUX2etSPDecxtYsfAmYx1eXFfqUT0pIyKNeVzf11oGDy/YvNTtvTweau/xc6OfHrlUeXVJoyXY9LwQRp8AQPrMYAQuJ7/4A//wQAMwAAMwECeAYRAGTyxZeYDDMDAYmFO7646Oy3fyXLx6faLE5yWj8yNF7vT4s8N+ahFFCcGG4oB16SDvyYhBNLW6G9hAAZgAAZgYAoGEAK50T74G+0pGhZ57nKH7V8a8uj6MW1jI/2j9/fywQ1zvJHydpnNTdne/rxM+rdNxYFyDp01hEDawKG3AepPG4ABGICBaRhACGTgubrYkVmC1ixVtUvg1LI3/Ly6n/HdFnxnxak75nQ036fLSsO2opaZjlbmNBeNMS/Gfibg0izvnm4hxvKsyGa5bhyTg+3DXr2zvZgcEP9jtiXymn9/t0qMEAL3M66rsMA5sAADMAADMDAmAwiBDDq2MwDH7/gdBmAABmAABmAABooMIAQy6Btz0Ede8AQDMAADMCAMIARyA1q8ARVI2NJhwAAMwAAMwAAMwMBmGUAI3Ky/4Rt/wwAMwAAMHAoDCIEIgQiBMAADMAADMAADMAADM2MAIZAB6aEMSKknrMMADMDAZhlACJzZTR8NYLMNAH/jbxiAARiAARiAgTkygBAIl3PkEpvgEgZgAAZ2nwGEQIRAZgDAAAzAAAzAAAzAAAzMjAGEwN0faDFYJoYwAAMwAANzZAAhcGY3fXOEBJvovGAABmAABmAABmBgswwgBG7W3/CNv2EABmAABg6FAYRAhEBmAMAADMAADMAADMAADMyMAYRABqSHMiClnrAOAzAAA5tlACFwZjd9NIDNNgD8jb9hAAZgAAZgAAbmyABCIFzOkUtsgksYgAEY2H0GEAIRApkBAAMwAAMwAAMwAAMwMDMGEAJ3f6DFYJkYwgAMwAAMzJEBhMCZ3fTNERJsovOCARiAARiAARiAgc0ygBC4WX/DN/6GARiAARg4FAYQAhECmQEAAzAAAzAAAzAAAzAwMwYQAhmQHsqAlHrCOgzAAAxslgGEwJnd9NEANtsA8Df+hgEYgAEYgAEYmCMDCIFwOUcusQkuYQAGYGD3GUAIRAhkBgAMwAAMwAAMwAAMwMDMGEAI3P2BFoNlYggDMAADMDBHBhACZ3bTN0dIsInOCwZgAAZgAAZgAAY2ywBC4Gb9Dd/4GwZgAAZg4FAYQAhECGQGAAzAAAzAAAzAAAzAwMwYQAhkQHooA1LqCeswAAMwsFkGEAJndtNHA9hsA8Df+BsGYAAGYAAGYGCODCAEwuUcucQmuIQBGICB3WcAIRAhkBkAMAADMAADMAADMAADM2MAIXD3B1oMlokhDMAADMDAHBlACJzZTd8cIcEmOi8YgAEYgAEYgAEY2CwDCIGb9Td8428YgAEYgIFDYQAhECGQGQAwAAMwAAMwAAMwAAMzYwAhkAHpoQxIqSeswwAMwMBmGUAInNlNHw1gsw0Af+NvGIABGIABGICBOTKAEAiXc+QSm+ASBmAABnafAYRAhEBmAMAADMAADMAADMAADMyMAYTA3R9oMVgmhjAAAzAAA3NkACFwZjd9c4QEm+i8YAAGYAAGYAAGYGCzDCAEbtbf8I2/YQAGYAAGDoUBhECEQGYAwAAMwAAMwAAMwAAMzIwBhEAGpIcyIKWesA4DMAADm2UAIXBmN300gM02APyNv2EABmAABmAABubIAEIgXM6RS2yCSxiAARjYfQYQAhECmQEAAzAAAzAAAzAAAzAwMwYQAnd/oMVgmRjCAAzAAAzMkQGEwJnd9M0REmyi84IBGIABGIABGICBzTKAELhZf8M3/oYBGIABGDgUBhACEQKZAQADMAADMAADMAADMDAzBhACGZAeyoCUesI6DMAADGyWAYTAmd300QA22wDwN/6GARiAARiAARiYIwMIgXA5Ry6xCS5hAAZgYPcZQAhECDzYGQDH1x+ZR9ePJ6j/qbmzvGNOYWsC3+5+p8uFkxjCAAzAAAz0YQAhEE76cEIaOIEBGIABGBjKAEJgm1jzxH83//v0HfNP1ed/v/Cfd1PY+K//ZP7bPWP+29Uru2l/W4xWPGZFwGVRrDs2Vx/eNLcfvmZeKuT/7OtvmNsPb5q3Xn8m61OX/4Mb5rhw/tCGmkv/wa9/wRx9/TFX/lPf/v36ey7tfPd9yDz//d83z1+i855vjIgNsYEBGICBbTCAEAh32+COMuEOBmAABvafAYTAolDzsrlx+o7ZWfFP1wshMBTrXrxhHi0fmRsvZhr45decAHjZCX05IfAZc/kdKwC+7MTCkhC4WBybGw+WZnn3NCxbx2XN7wiBmfit6VMuevgUBmAABmBgLgwgBMLiXFjEDliEARiAgf1iACGwJBy42YD/y/yPJ/Yr4DTghTm9WxLojs3Vd142zy4Wxs/4S4VAu//qZcuEnzVYFgIXZtEmOJa4G7C/mQX4mPn8m7s6q44ZgbRJ+lgYgAEYgIEcAwiBcJHjgn1wAQMwAAMwsC4DCIEl4aVVCPzP5n98o1ky/E+nsWBoZxPafTpdnKYHvJfOzP2LC3NRfe5fOxo4u+ym+ZN7xpxUn3Rp8BXzhz825k++6beS7k++2cM25bfj69fM8u6XzeLV75jl8gf+Y3+rNMExmyY4/mVzZ3nN3HjRbqvz3e/QDldOfVzSfUc9i+8Zc+OB7P+BWT74RmZprn1+X2E2oLK3JAQ2deohBFazAvPPIaxmDBaXJ4d1b8pdmMWlT5uvfv/3C59Pm6dUPYLzMvutmNjkFZ1ry3nzCfPBoLwozcKLkE0eXzCf/0Jse5xGi5YiBPqtzyeTR2DD73u7MvXpqi/H49jwGyZgAAZgYK4MIATC5lzZxC7YhAEYgIHdZgAhMBIT/ssL/6t+JqA8G9Bvv2tecWkrce+rLzdC13/6rgnFQL+s2J4nS4tdvt/47+a/ROUVG1AlAp5fEcBOzPnFhRkuBtrzvdBXEgKtACji38ev/l9zcu//uFlxRduiOjQCnYhyXtC786rY/mVzRwt/L37DPFr+wATHncBnxUB/zundSMhzImNz3AuLUp49pxIBVTlJHtbuV++0PBtQ7C3PCGx80kcIXBj3rMDs8uA1hEDnfz0L0IpoGfEsilNju6+nEwGt0Fels0uNv/p9JfSJ+FanqQS9b3+oYj/+LSKltiWTJrBLBMDmnNiuxReeMEcr1C+uL78bvvEFvoABGICB+TOAEDj/GNGOiBEMwAAMwMAuMoAQGIgSCuLSjMDsfi8Oiui3WGSeL+jEQhETVTmF8o+u3TcXt04asXGxMG7fvTNzVDinDGC7EBgIhO55gv/X/OF/7bZRyvNCYCrKPbqef5GGiHbN8Vg4tIKdnV3Y5FnPOqzrLrMIKzuduNikd7a5fUo8XFTCXI+XeIwzI7B/eeLL/lsl/jmhTAl4tY/aYqjOr9N7Ua5+cYcTAqN87T4RBrMCnRf+5CUmfvZilEddnrUvKtMei8t15ezqy1DaYsCx/rzjK3wFAzBweAwgBB5ezGnnxBwGYAAGYGATDCAEBqKEgi4r+C3MoiDovfLVd8w/1bMEvRB44z+p/ErlFPaf3GqWBMvSYLedqxCYXYbb1N/NzouW9Q4RAr0w2Ih6ifiolyUH5TTn2AbV922+cxYCw+W8emnvALGsEteaJb1NPp1CoMwajAW7imVnXzVr0M0yFOEwy3oPIdCeF9lb25jNs+FuE50oZeBvGIABGICBKRhACISrKbgiT7iCARiAARhACCwJCSUhMLs/PyNwHSEwNyNw9Qa7gRmBLUJgItpVy3iHC4Hq+X/xMwRzMwJzsZ3N0uA1Ox8njFUz7fQsvVyds/tyMwIjmzJCXyDsORuaJb2ezwlmBMb2O7viciPb43P4HcwuXr0vwc/4DgZgAAY2xQBCIKxtijXKgTUYgAEYOCwGEAJLAkFW8LNwpM8I9M8V1Mt+158RuEieEbgOmNsVAuNn9Xlh8AdmiBBo82jS53yRPiMw35nZl4Us1fMJc3mN9YxA/xzA0V8WYpm1IpzMtFtJCFyY5Fl8cVtIhEA/e69e9isvCqmfGbgwyXMGq6W/X1Vpwrj0nBGobcsKkPk4hmWRBn/AAAzAAAzsDgMIgbsTK9oVsYIBGIABGNglBhACtcCgvxeFQAt48zKQ8EUiAv8IQqC1JXprsF0aPOhlId/8P/Ubg+WNwG77tzer2UEZgXDVZwS2zAhcLPTbgP0bg0Nhr/sZgYvqBSP1W4mr5b/NC0es76O3Bts0GbtO7y7NMvsCj2fM5XdumtsP488b5vJRFdvLr2WO3zS33z5OZ1y9eMM8Kr6heM2XhSjxz4lvRaFNmMxv02XG6nl+TghslgzbZcTpklwv5DVLjNX5dXuK0+h8egiBvezI12+XOmNsJYYwAAMwAAOaAYRAeNA88B0eYAAGYAAGxmIAIbAWK4BqLKjGz8cLfPGMwHTJcc8YOoGue1bgevVomw3Y085ts5nMCNwRu7ftN8pPRXF8gk9gAAZgYDADCIHcd6x3L4r/8B8MwAAMwECeAYRAbkwH35huvjH5GYOxEBgvOR5il3tpyPKOOZ0o/n1fSjLE5o2nRQjcgbaR79g3zspE7Yh6EF8YgIFDZgAhEP4PmX/qDv8wAAMwMB0DCIEMYHdD7MgtDc4s+x3SWVixLv/8vnUbnH0O4XQi45A6rpUWIXA32gZ9GHGCARiAgb1kACFw3fsxzl/rPpB+ZS/7FZigX4ABGLAMIARykeMiBwMwAAMwAAMwAAMwMDMGEAIZrDFghwEYgAEYgIEpGEAInNlN3xRBJk86DxiAARiAARiAARjYLQYQAncrXrQv4gUDMAADMLArDCAEIgQyAwAGYAAGYAAGYAAGYGBmDCAEMqDclQEldsIqDMAADOwWAwiBM7vpowHtVgMiXsQLBmAABmAABmBgCgYQAuFqCq7IE65gAAZgAAYQAhECmQEAAzAAAzAAAzAAAzAwMwYQAhmoMViHARiAARiAgSkYQAic2U3fFEEmTzoPGIABGIABGIABGNgtBhACdytetC/iBQMwAAMwsCsMIAQiBDIDAAZgAAZgAAZgAAZgYGYMIAQyoNyVASV2wioMwAAM7BYDCIEzu+mjAe1WAyJexAsGYAAGYAAGYGAKBhAC4WoKrsgTrmAABmAABhACEQKZAQADMAADMAADMPD/t2sHJgDEMAzE9t86UxhyoAXKQ5SnNmWAgWcGFIGCmrDOAAMMMMDAwoAi8NmlbzFkZ/p5MMAAAwwwwAADLQOKwNa87Jd5McAAAwxUDCgCFYFeADDAAAMMMMAAAww8M6AIFCgrgdJ3ssoAAwy0DCgCn136LFBrgczLvBhggAEGGGBgYUARyNXClTO5YoABBhhQBCoCvQBggAEGGGCAAQYYeGZAESioCesMMMAAAwwsDCgCn136FkN2pp8HAwwwwAADDDDQMqAIbM3LfpkXAwwwwEDFgCJQEegFAAMMMMAAAwwwwMAzA4pAgbISKH0nqwwwwEDLgCLw2aXPArUWyLzMiwEGGGCAAQYWBhSBXC1cOZMrBhhggAFFoCLQCwAGGGCAAQYYYICBZwYUgYKasM4AAwwwwMDCwAGC9uip2Dd90gAAAABJRU5ErkJggg==)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTdJTGm4kxQf",
        "outputId": "d23cedf8-8e19-4092-f036-359c043d66ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "print_cm(confusion_matrix, labels=LABEL.vocab.itos[1:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             participants           units on a scale percentage of participants                     months                       days             percent change                      hours                      ng/ml                      mg/dl                       mmhg                     liters                      ratio                    minutes                 percentage                         mm                     titers                      pg/ml                     mmol/l                      weeks                    seconds \n",
            "                  participants                     4360.0                       62.0                      236.0                       10.0                        7.0                        5.0                        6.0                       14.0                       19.0                        1.0                        4.0                        4.0                        0.0                        2.0                        2.0                        4.0                        7.0                        3.0                        1.0                        4.0 \n",
            "              units on a scale                       38.0                     3399.0                       14.0                        0.0                        1.0                       12.0                        2.0                        2.0                        6.0                        0.0                        0.0                        1.0                        1.0                        0.0                       14.0                        0.0                        0.0                        0.0                        0.0                        3.0 \n",
            "    percentage of participants                      168.0                        9.0                     2304.0                       16.0                        3.0                        3.0                        0.0                        3.0                        1.0                        0.0                        0.0                        0.0                        0.0                        2.0                        0.0                        0.0                        0.0                        1.0                        0.0                        0.0 \n",
            "                        months                       10.0                        3.0                       10.0                      501.0                       20.0                        0.0                        1.0                        2.0                        0.0                        0.0                        0.0                        1.0                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                        3.0                        0.0 \n",
            "                          days                        9.0                        4.0                        2.0                       85.0                      250.0                        0.0                       14.0                        0.0                        2.0                        1.0                        0.0                        0.0                        1.0                        3.0                        0.0                        0.0                        0.0                        1.0                        1.0                        1.0 \n",
            "                percent change                        0.0                       11.0                        3.0                        0.0                        0.0                      353.0                        0.0                        6.0                        1.0                        1.0                        0.0                        0.0                        1.0                        4.0                        0.0                        0.0                        0.0                        0.0                        0.0                        4.0 \n",
            "                         hours                        7.0                        5.0                        2.0                        1.0                        6.0                        0.0                      302.0                        5.0                        4.0                        0.0                        1.0                        2.0                        6.0                        2.0                        1.0                        0.0                        1.0                        0.0                        0.0                        3.0 \n",
            "                         ng/ml                        5.0                        1.0                        0.0                        0.0                        0.0                        1.0                        2.0                      321.0                        2.0                        0.0                        1.0                        0.0                        0.0                        1.0                        1.0                        0.0                       10.0                        1.0                        0.0                        0.0 \n",
            "                         mg/dl                        1.0                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                       10.0                      184.0                        0.0                        0.0                        1.0                        0.0                        1.0                        0.0                        0.0                        2.0                       12.0                        0.0                        1.0 \n",
            "                          mmhg                        3.0                        2.0                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                        3.0                      226.0                        0.0                        0.0                        0.0                        0.0                        1.0                        0.0                        0.0                        0.0                        0.0                        0.0 \n",
            "                        liters                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                        1.0                        2.0                        0.0                        0.0                      217.0                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0 \n",
            "                         ratio                        5.0                        4.0                        3.0                        0.0                        0.0                        3.0                        0.0                        2.0                        3.0                        0.0                        1.0                      144.0                        1.0                        1.0                        0.0                        1.0                        5.0                        0.0                        1.0                        0.0 \n",
            "                       minutes                        1.0                        3.0                        1.0                        0.0                        6.0                        1.0                       32.0                        1.0                        1.0                        1.0                        0.0                        0.0                      129.0                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                        6.0 \n",
            "                    percentage                        3.0                        1.0                       25.0                        2.0                        0.0                       17.0                        1.0                        3.0                        1.0                        0.0                        1.0                        2.0                        0.0                       60.0                        2.0                        0.0                        0.0                        0.0                        0.0                        0.0 \n",
            "                            mm                        4.0                       19.0                        0.0                        0.0                        0.0                        0.0                        0.0                        6.0                        2.0                        2.0                        0.0                        2.0                        0.0                        0.0                       98.0                        0.0                        0.0                        0.0                        0.0                        0.0 \n",
            "                        titers                        1.0                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                      143.0                        0.0                        0.0                        0.0                        0.0 \n",
            "                         pg/ml                        2.0                        1.0                        1.0                        0.0                        0.0                        0.0                        1.0                       32.0                        0.0                        1.0                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                       74.0                        1.0                        0.0                        1.0 \n",
            "                        mmol/l                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                        5.0                       37.0                        0.0                        0.0                        1.0                        0.0                        1.0                        0.0                        0.0                        0.0                       80.0                        0.0                        0.0 \n",
            "                         weeks                        4.0                        0.0                        4.0                       67.0                        5.0                        0.0                        5.0                        0.0                        0.0                        0.0                        0.0                        0.0                        1.0                        0.0                        0.0                        0.0                        0.0                        0.0                       28.0                        0.0 \n",
            "                       seconds                        0.0                        1.0                        0.0                        0.0                        0.0                        2.0                        2.0                        2.0                        1.0                        3.0                        1.0                        0.0                        7.0                        0.0                        0.0                        0.0                        0.0                        0.0                        0.0                       71.0 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGRowU5A2qfY",
        "outputId": "67d84e53-8ec3-493b-a524-da5df5d1d7bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(f1_score(lab, preds, average='macro'))\n",
        "print(f1_score(lab, preds, average='micro'))\n",
        "print(f1_score(lab, preds, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.811664646354368\n",
            "0.9060682766641581\n",
            "0.9042233619076105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulE72NLk-3_"
      },
      "source": [
        "confusion_matrix_df = pd.DataFrame(confusion_matrix.numpy(), columns=LABEL.vocab.itos[1:], index=LABEL.vocab.itos[1:])\n",
        "confusion_matrix_df.to_csv('confusion_matrix_v2_wideSA_2020_09_29.csv', index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0G7HAFsTF7P",
        "outputId": "09d2c238-8372-4857-b1d4-47ac52d7bea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "token_embedding.weight \t torch.Size([50000, 128])\n",
            "pos_embedding.weight \t torch.Size([512, 128])\n",
            "tblocks.0.attention.tokeys.weight \t torch.Size([16, 16])\n",
            "tblocks.0.attention.toqueries.weight \t torch.Size([16, 16])\n",
            "tblocks.0.attention.tovalues.weight \t torch.Size([16, 16])\n",
            "tblocks.0.attention.unifyheads.weight \t torch.Size([128, 128])\n",
            "tblocks.0.attention.unifyheads.bias \t torch.Size([128])\n",
            "tblocks.0.norm1.weight \t torch.Size([128])\n",
            "tblocks.0.norm1.bias \t torch.Size([128])\n",
            "tblocks.0.norm2.weight \t torch.Size([128])\n",
            "tblocks.0.norm2.bias \t torch.Size([128])\n",
            "tblocks.0.ff.0.weight \t torch.Size([512, 128])\n",
            "tblocks.0.ff.0.bias \t torch.Size([512])\n",
            "tblocks.0.ff.2.weight \t torch.Size([128, 512])\n",
            "tblocks.0.ff.2.bias \t torch.Size([128])\n",
            "tblocks.1.attention.tokeys.weight \t torch.Size([16, 16])\n",
            "tblocks.1.attention.toqueries.weight \t torch.Size([16, 16])\n",
            "tblocks.1.attention.tovalues.weight \t torch.Size([16, 16])\n",
            "tblocks.1.attention.unifyheads.weight \t torch.Size([128, 128])\n",
            "tblocks.1.attention.unifyheads.bias \t torch.Size([128])\n",
            "tblocks.1.norm1.weight \t torch.Size([128])\n",
            "tblocks.1.norm1.bias \t torch.Size([128])\n",
            "tblocks.1.norm2.weight \t torch.Size([128])\n",
            "tblocks.1.norm2.bias \t torch.Size([128])\n",
            "tblocks.1.ff.0.weight \t torch.Size([512, 128])\n",
            "tblocks.1.ff.0.bias \t torch.Size([512])\n",
            "tblocks.1.ff.2.weight \t torch.Size([128, 512])\n",
            "tblocks.1.ff.2.bias \t torch.Size([128])\n",
            "tblocks.2.attention.tokeys.weight \t torch.Size([16, 16])\n",
            "tblocks.2.attention.toqueries.weight \t torch.Size([16, 16])\n",
            "tblocks.2.attention.tovalues.weight \t torch.Size([16, 16])\n",
            "tblocks.2.attention.unifyheads.weight \t torch.Size([128, 128])\n",
            "tblocks.2.attention.unifyheads.bias \t torch.Size([128])\n",
            "tblocks.2.norm1.weight \t torch.Size([128])\n",
            "tblocks.2.norm1.bias \t torch.Size([128])\n",
            "tblocks.2.norm2.weight \t torch.Size([128])\n",
            "tblocks.2.norm2.bias \t torch.Size([128])\n",
            "tblocks.2.ff.0.weight \t torch.Size([512, 128])\n",
            "tblocks.2.ff.0.bias \t torch.Size([512])\n",
            "tblocks.2.ff.2.weight \t torch.Size([128, 512])\n",
            "tblocks.2.ff.2.bias \t torch.Size([128])\n",
            "tblocks.3.attention.tokeys.weight \t torch.Size([16, 16])\n",
            "tblocks.3.attention.toqueries.weight \t torch.Size([16, 16])\n",
            "tblocks.3.attention.tovalues.weight \t torch.Size([16, 16])\n",
            "tblocks.3.attention.unifyheads.weight \t torch.Size([128, 128])\n",
            "tblocks.3.attention.unifyheads.bias \t torch.Size([128])\n",
            "tblocks.3.norm1.weight \t torch.Size([128])\n",
            "tblocks.3.norm1.bias \t torch.Size([128])\n",
            "tblocks.3.norm2.weight \t torch.Size([128])\n",
            "tblocks.3.norm2.bias \t torch.Size([128])\n",
            "tblocks.3.ff.0.weight \t torch.Size([512, 128])\n",
            "tblocks.3.ff.0.bias \t torch.Size([512])\n",
            "tblocks.3.ff.2.weight \t torch.Size([128, 512])\n",
            "tblocks.3.ff.2.bias \t torch.Size([128])\n",
            "tblocks.4.attention.tokeys.weight \t torch.Size([16, 16])\n",
            "tblocks.4.attention.toqueries.weight \t torch.Size([16, 16])\n",
            "tblocks.4.attention.tovalues.weight \t torch.Size([16, 16])\n",
            "tblocks.4.attention.unifyheads.weight \t torch.Size([128, 128])\n",
            "tblocks.4.attention.unifyheads.bias \t torch.Size([128])\n",
            "tblocks.4.norm1.weight \t torch.Size([128])\n",
            "tblocks.4.norm1.bias \t torch.Size([128])\n",
            "tblocks.4.norm2.weight \t torch.Size([128])\n",
            "tblocks.4.norm2.bias \t torch.Size([128])\n",
            "tblocks.4.ff.0.weight \t torch.Size([512, 128])\n",
            "tblocks.4.ff.0.bias \t torch.Size([512])\n",
            "tblocks.4.ff.2.weight \t torch.Size([128, 512])\n",
            "tblocks.4.ff.2.bias \t torch.Size([128])\n",
            "tblocks.5.attention.tokeys.weight \t torch.Size([16, 16])\n",
            "tblocks.5.attention.toqueries.weight \t torch.Size([16, 16])\n",
            "tblocks.5.attention.tovalues.weight \t torch.Size([16, 16])\n",
            "tblocks.5.attention.unifyheads.weight \t torch.Size([128, 128])\n",
            "tblocks.5.attention.unifyheads.bias \t torch.Size([128])\n",
            "tblocks.5.norm1.weight \t torch.Size([128])\n",
            "tblocks.5.norm1.bias \t torch.Size([128])\n",
            "tblocks.5.norm2.weight \t torch.Size([128])\n",
            "tblocks.5.norm2.bias \t torch.Size([128])\n",
            "tblocks.5.ff.0.weight \t torch.Size([512, 128])\n",
            "tblocks.5.ff.0.bias \t torch.Size([512])\n",
            "tblocks.5.ff.2.weight \t torch.Size([128, 512])\n",
            "tblocks.5.ff.2.bias \t torch.Size([128])\n",
            "toprobs.weight \t torch.Size([20, 128])\n",
            "toprobs.bias \t torch.Size([20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHLMY4sgTKof"
      },
      "source": [
        "torch.save(model.state_dict(), 'clin_trials_unit_model_v2_2020_09_29_narrow_sa.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwF-3q5QUB9O",
        "outputId": "58859d8b-3a42-415e-fef6-bb914d0d40da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "    \n",
        "count_parameters(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------+------------+\n",
            "|                Modules                | Parameters |\n",
            "+---------------------------------------+------------+\n",
            "|         token_embedding.weight        |  6400000   |\n",
            "|          pos_embedding.weight         |   65536    |\n",
            "|   tblocks.0.attention.tokeys.weight   |    256     |\n",
            "|  tblocks.0.attention.toqueries.weight |    256     |\n",
            "|  tblocks.0.attention.tovalues.weight  |    256     |\n",
            "| tblocks.0.attention.unifyheads.weight |   16384    |\n",
            "|  tblocks.0.attention.unifyheads.bias  |    128     |\n",
            "|         tblocks.0.norm1.weight        |    128     |\n",
            "|          tblocks.0.norm1.bias         |    128     |\n",
            "|         tblocks.0.norm2.weight        |    128     |\n",
            "|          tblocks.0.norm2.bias         |    128     |\n",
            "|         tblocks.0.ff.0.weight         |   65536    |\n",
            "|          tblocks.0.ff.0.bias          |    512     |\n",
            "|         tblocks.0.ff.2.weight         |   65536    |\n",
            "|          tblocks.0.ff.2.bias          |    128     |\n",
            "|   tblocks.1.attention.tokeys.weight   |    256     |\n",
            "|  tblocks.1.attention.toqueries.weight |    256     |\n",
            "|  tblocks.1.attention.tovalues.weight  |    256     |\n",
            "| tblocks.1.attention.unifyheads.weight |   16384    |\n",
            "|  tblocks.1.attention.unifyheads.bias  |    128     |\n",
            "|         tblocks.1.norm1.weight        |    128     |\n",
            "|          tblocks.1.norm1.bias         |    128     |\n",
            "|         tblocks.1.norm2.weight        |    128     |\n",
            "|          tblocks.1.norm2.bias         |    128     |\n",
            "|         tblocks.1.ff.0.weight         |   65536    |\n",
            "|          tblocks.1.ff.0.bias          |    512     |\n",
            "|         tblocks.1.ff.2.weight         |   65536    |\n",
            "|          tblocks.1.ff.2.bias          |    128     |\n",
            "|   tblocks.2.attention.tokeys.weight   |    256     |\n",
            "|  tblocks.2.attention.toqueries.weight |    256     |\n",
            "|  tblocks.2.attention.tovalues.weight  |    256     |\n",
            "| tblocks.2.attention.unifyheads.weight |   16384    |\n",
            "|  tblocks.2.attention.unifyheads.bias  |    128     |\n",
            "|         tblocks.2.norm1.weight        |    128     |\n",
            "|          tblocks.2.norm1.bias         |    128     |\n",
            "|         tblocks.2.norm2.weight        |    128     |\n",
            "|          tblocks.2.norm2.bias         |    128     |\n",
            "|         tblocks.2.ff.0.weight         |   65536    |\n",
            "|          tblocks.2.ff.0.bias          |    512     |\n",
            "|         tblocks.2.ff.2.weight         |   65536    |\n",
            "|          tblocks.2.ff.2.bias          |    128     |\n",
            "|   tblocks.3.attention.tokeys.weight   |    256     |\n",
            "|  tblocks.3.attention.toqueries.weight |    256     |\n",
            "|  tblocks.3.attention.tovalues.weight  |    256     |\n",
            "| tblocks.3.attention.unifyheads.weight |   16384    |\n",
            "|  tblocks.3.attention.unifyheads.bias  |    128     |\n",
            "|         tblocks.3.norm1.weight        |    128     |\n",
            "|          tblocks.3.norm1.bias         |    128     |\n",
            "|         tblocks.3.norm2.weight        |    128     |\n",
            "|          tblocks.3.norm2.bias         |    128     |\n",
            "|         tblocks.3.ff.0.weight         |   65536    |\n",
            "|          tblocks.3.ff.0.bias          |    512     |\n",
            "|         tblocks.3.ff.2.weight         |   65536    |\n",
            "|          tblocks.3.ff.2.bias          |    128     |\n",
            "|   tblocks.4.attention.tokeys.weight   |    256     |\n",
            "|  tblocks.4.attention.toqueries.weight |    256     |\n",
            "|  tblocks.4.attention.tovalues.weight  |    256     |\n",
            "| tblocks.4.attention.unifyheads.weight |   16384    |\n",
            "|  tblocks.4.attention.unifyheads.bias  |    128     |\n",
            "|         tblocks.4.norm1.weight        |    128     |\n",
            "|          tblocks.4.norm1.bias         |    128     |\n",
            "|         tblocks.4.norm2.weight        |    128     |\n",
            "|          tblocks.4.norm2.bias         |    128     |\n",
            "|         tblocks.4.ff.0.weight         |   65536    |\n",
            "|          tblocks.4.ff.0.bias          |    512     |\n",
            "|         tblocks.4.ff.2.weight         |   65536    |\n",
            "|          tblocks.4.ff.2.bias          |    128     |\n",
            "|   tblocks.5.attention.tokeys.weight   |    256     |\n",
            "|  tblocks.5.attention.toqueries.weight |    256     |\n",
            "|  tblocks.5.attention.tovalues.weight  |    256     |\n",
            "| tblocks.5.attention.unifyheads.weight |   16384    |\n",
            "|  tblocks.5.attention.unifyheads.bias  |    128     |\n",
            "|         tblocks.5.norm1.weight        |    128     |\n",
            "|          tblocks.5.norm1.bias         |    128     |\n",
            "|         tblocks.5.norm2.weight        |    128     |\n",
            "|          tblocks.5.norm2.bias         |    128     |\n",
            "|         tblocks.5.ff.0.weight         |   65536    |\n",
            "|          tblocks.5.ff.0.bias          |    512     |\n",
            "|         tblocks.5.ff.2.weight         |   65536    |\n",
            "|          tblocks.5.ff.2.bias          |    128     |\n",
            "|             toprobs.weight            |    2560    |\n",
            "|              toprobs.bias             |     20     |\n",
            "+---------------------------------------+------------+\n",
            "Total Trainable Params: 7365140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7365140"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHlb9-MCUT4P",
        "outputId": "e868eb3f-6380-4ec3-8f9f-56c00d86fa61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CTransformer(\n",
              "  (token_embedding): Embedding(50000, 128)\n",
              "  (pos_embedding): Embedding(512, 128)\n",
              "  (tblocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (attention): SelfAttentionNarrow(\n",
              "        (tokeys): Linear(in_features=16, out_features=16, bias=False)\n",
              "        (toqueries): Linear(in_features=16, out_features=16, bias=False)\n",
              "        (tovalues): Linear(in_features=16, out_features=16, bias=False)\n",
              "        (unifyheads): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "      )\n",
              "      (do): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (attention): SelfAttentionNarrow(\n",
              "        (tokeys): Linear(in_features=16, out_features=16, bias=False)\n",
              "        (toqueries): Linear(in_features=16, out_features=16, bias=False)\n",
              "        (tovalues): Linear(in_features=16, out_features=16, bias=False)\n",
              "        (unifyheads): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "      )\n",
              "      (do): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (attention): SelfAttentionNarrow(\n",
              "        (tokeys): Linear(in_features=16, out_features=16, bias=False)\n",
              "        (toqueries): Linear(in_features=16, out_features=16, bias=False)\n",
              "        (tovalues): Linear(in_features=16, out_features=16, bias=False)\n",
              "        (unifyheads): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "      )\n",
              "      (do): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (attention): SelfAttentionNarrow(\n",
              "        (tokeys): Linear(in_features=16, out_features=16, bias=False)\n",
              "        (toqueries): Linear(in_features=16, out_features=16, bias=False)\n",
              "        (tovalues): Linear(in_features=16, out_features=16, bias=False)\n",
              "        (unifyheads): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "      )\n",
              "      (do): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (attention): SelfAttentionNarrow(\n",
              "        (tokeys): Linear(in_features=16, out_features=16, bias=False)\n",
              "        (toqueries): Linear(in_features=16, out_features=16, bias=False)\n",
              "        (tovalues): Linear(in_features=16, out_features=16, bias=False)\n",
              "        (unifyheads): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "      )\n",
              "      (do): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (attention): SelfAttentionNarrow(\n",
              "        (tokeys): Linear(in_features=16, out_features=16, bias=False)\n",
              "        (toqueries): Linear(in_features=16, out_features=16, bias=False)\n",
              "        (tovalues): Linear(in_features=16, out_features=16, bias=False)\n",
              "        (unifyheads): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "      )\n",
              "      (do): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (toprobs): Linear(in_features=128, out_features=20, bias=True)\n",
              "  (do): Dropout(p=0.0, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWfRKaZHpwvq"
      },
      "source": [
        "# Demonstrating model on mini test sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVAro_5vdbWJ"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "class DataFrameDataset(data.Dataset):\n",
        "     \"\"\"Class for using pandas DataFrames as a datasource\"\"\"\n",
        "     def __init__(self, examples, fields, filter_pred=None):\n",
        "         \"\"\"\n",
        "         Create a dataset from a pandas dataframe of examples and Fields\n",
        "         Arguments:\n",
        "             examples pd.DataFrame: DataFrame of examples\n",
        "             fields {str: Field}: The Fields to use in this tuple. The\n",
        "                 string is a field name, and the Field is the associated field.\n",
        "             filter_pred (callable or None): use only exanples for which\n",
        "                 filter_pred(example) is true, or use all examples if None.\n",
        "                 Default is None\n",
        "         \"\"\"\n",
        "         self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()\n",
        "         if filter_pred is not None:\n",
        "             self.examples = filter(filter_pred, self.examples)\n",
        "         self.fields = dict(fields)\n",
        "         # Unpack field tuples\n",
        "         for n, f in list(self.fields.items()):\n",
        "             if isinstance(n, tuple):\n",
        "                 self.fields.update(zip(n, f))\n",
        "                 del self.fields[n]\n",
        "\n",
        "class SeriesExample(data.Example):\n",
        "     \"\"\"Class to convert a pandas Series to an Example\"\"\"\n",
        "    \n",
        "     @classmethod\n",
        "     def fromSeries(cls, data, fields):\n",
        "         return cls.fromdict(data.to_dict(), fields)\n",
        "\n",
        "     @classmethod\n",
        "     def fromdict(cls, data, fields):\n",
        "         ex = cls()\n",
        "         \n",
        "         for key, field in fields.items():\n",
        "             if key not in data:\n",
        "                 raise ValueError(\"Specified key {} was not found in \"\n",
        "                 \"the input data\".format(key))\n",
        "             if field is not None:\n",
        "                 setattr(ex, key, field.preprocess(data[key]))\n",
        "             else:\n",
        "                 setattr(ex, key, data[key])\n",
        "         return ex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTHTw2gsdjLM"
      },
      "source": [
        "fields = { 'mini_unit' : LABEL, 'mini_text' : TEXT } "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGWc8emfdclM"
      },
      "source": [
        "my_df = pd.DataFrame({'mini_unit': ['units on a scale', 'months', 'ng/ml', 'participants', 'mmhg'], \n",
        "                      'mini_text': ['We used Likert scale with questions on happiness.',\n",
        "                                    'This study will measure the time until death for people with colon cancer stage IV after being treated chemotherapy.',\n",
        "                                    'Concentration (Steady State) of Imatinib During Cycle One (Pharmacokinetics) Blood collected before and at 1,2,4 ad 24 hours after ingestion of imatinib on day 8 of cycle 1 result is the measurement of the before dosing on day 8 (trough level) and the 24 hour dosing day 8',\n",
        "                                    'Measure how many participants were counted in the control versus treated group',\n",
        "                                    'We will report the blood pressure.']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrXA_hP0iDiq"
      },
      "source": [
        "test_ds = DataFrameDataset(my_df, fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCQyO3tmZPmj"
      },
      "source": [
        "mini_test_iter = data.BucketIterator(test_ds, batch_size=1, device=device, sort_key=lambda x: len(x.mini_text), #  https://github.com/pytorch/text/issues/474\n",
        "                                     train=False,\n",
        "                                     sort_within_batch=False) # per link above, False bc w want to wrap this Iterator layer. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4_0gKYni7RX"
      },
      "source": [
        "my_df['len_text'] = my_df['mini_text'].apply(lambda x: len(x.split(' ')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFiXCSQJ8cP1",
        "outputId": "e368320a-5385-49bd-d5cc-4cb78fc74599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "my_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mini_unit</th>\n",
              "      <th>mini_text</th>\n",
              "      <th>len_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>units on a scale</td>\n",
              "      <td>We used Likert scale with questions on happiness.</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>months</td>\n",
              "      <td>This study will measure the time until death f...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ng/ml</td>\n",
              "      <td>Concentration (Steady State) of Imatinib Durin...</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>participants</td>\n",
              "      <td>Measure how many participants were counted in ...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mmhg</td>\n",
              "      <td>We will report the blood pressure.</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          mini_unit  ... len_text\n",
              "0  units on a scale  ...        8\n",
              "1            months  ...       19\n",
              "2             ng/ml  ...       48\n",
              "3      participants  ...       12\n",
              "4              mmhg  ...        6\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON5z0U1UZl-d",
        "outputId": "58009884-ee1e-4c3f-9386-3086b88177cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "source": [
        "nb_classes = 20\n",
        "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
        "\n",
        "with torch.no_grad():\n",
        "      \n",
        "        model.train(False)\n",
        "        for batch in mini_test_iter:\n",
        "\n",
        "            input = batch.mini_text[0].to(device)\n",
        "            #print(input)\n",
        "            label = (batch.mini_unit - 1).to(device)\n",
        "            print(label)\n",
        "            if input.size(1) > mx:\n",
        "                input = input[:, :mx]\n",
        "            #out = model(input).argmax(dim=1) # .cpu().numpy() to get array\n",
        "            print(torch.exp(model(input)))\n",
        "            # print(out)\n",
        "\n",
        "            #for t, p in zip(label.view(-1), out.view(-1)):\n",
        "                #confusion_matrix[t.long(), p.long()] += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([9], device='cuda:0')\n",
            "tensor([[1.7762e-06, 2.6359e-11, 5.9104e-09, 2.9026e-11, 1.2369e-09, 1.7075e-09,\n",
            "         1.1313e-09, 7.3491e-08, 1.6109e-07, 1.0000e+00, 1.7226e-10, 6.5069e-08,\n",
            "         1.8982e-10, 2.7818e-09, 6.0258e-09, 9.0357e-09, 1.2017e-09, 3.8991e-07,\n",
            "         2.4585e-12, 1.4986e-10]], device='cuda:0')\n",
            "tensor([1], device='cuda:0')\n",
            "tensor([[1.5779e-02, 9.7738e-01, 6.7424e-03, 4.1000e-07, 6.2852e-09, 5.1278e-08,\n",
            "         1.2562e-08, 4.1929e-09, 8.7773e-07, 3.1500e-09, 2.6228e-11, 8.1692e-09,\n",
            "         4.3756e-09, 2.2831e-06, 4.0675e-05, 9.3010e-10, 2.4652e-08, 1.4785e-11,\n",
            "         1.3178e-08, 4.9644e-05]], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([[8.3253e-01, 4.7525e-07, 2.7472e-03, 2.0482e-04, 9.1765e-04, 1.7968e-06,\n",
            "         3.5966e-05, 5.7894e-03, 7.3540e-02, 7.2791e-05, 1.0387e-04, 5.0891e-04,\n",
            "         3.6020e-06, 1.2613e-05, 2.3004e-05, 6.1057e-02, 1.5848e-02, 6.5817e-03,\n",
            "         1.6302e-05, 3.3321e-06]], device='cuda:0')\n",
            "tensor([3], device='cuda:0')\n",
            "tensor([[2.3993e-02, 9.8654e-07, 1.3239e-01, 6.5680e-01, 7.3428e-04, 9.6834e-08,\n",
            "         3.7289e-02, 3.5847e-05, 2.1489e-06, 6.6516e-07, 1.6062e-03, 1.3837e-04,\n",
            "         9.0098e-03, 6.8928e-03, 4.0515e-08, 3.3443e-06, 6.1804e-03, 1.7709e-04,\n",
            "         9.1439e-02, 3.3307e-02]], device='cuda:0')\n",
            "tensor([7], device='cuda:0')\n",
            "tensor([[3.5379e-09, 1.0832e-11, 4.6113e-08, 1.2416e-11, 1.5153e-11, 1.4158e-06,\n",
            "         1.8356e-08, 9.9896e-01, 5.0027e-05, 3.1751e-09, 5.8173e-07, 1.8410e-06,\n",
            "         2.1125e-14, 2.2854e-07, 4.2353e-07, 9.7657e-08, 9.8116e-04, 2.0511e-07,\n",
            "         9.8439e-11, 3.4261e-13]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbjoT7zSAj2t"
      },
      "source": [
        "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
        "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
        "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
        "    empty_cell = \" \" * columnwidth\n",
        "    # Print header\n",
        "    print(\"    \" + empty_cell, end=\" \")\n",
        "    for label in labels:\n",
        "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
        "    print()\n",
        "    # Print rows\n",
        "    for i, label1 in enumerate(labels):\n",
        "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
        "        for j in range(len(labels)):\n",
        "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
        "            if hide_zeroes:\n",
        "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
        "            if hide_diagonal:\n",
        "                cell = cell if i != j else empty_cell\n",
        "            if hide_threshold:\n",
        "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
        "            print(cell, end=\" \")\n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On_zikhACndI"
      },
      "source": [
        "print_cm(confusion_matrix, labels=LABEL.vocab.itos[1:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wec36bRFaCzK",
        "outputId": "2d4afcca-64ee-4e94-a2d3-fbaee268caf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(LABEL.vocab.itos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', 'participants', 'units on a scale', 'percentage of participants', 'months', 'days', 'percent change', 'hours', 'ng/ml', 'mg/dl', 'mmhg', 'liters', 'ratio', 'minutes', 'percentage', 'mm', 'titers', 'pg/ml', 'mmol/l', 'weeks', 'seconds']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUcZUTXehWsX",
        "outputId": "85c6d930-cd13-4ccb-8a4f-88b49b2559fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "out.view(-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8h2ghG3_7tR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXHDzSWnslOX"
      },
      "source": [
        "# More Experiments\n",
        "- Every experiment below fails miserably using starting lr=0.0001 (accuracy like 1.5%. For the 256/16/12 model, epoch 1 has acc 32.5% w lr=0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogZwhDD3smXy",
        "outputId": "a63c8ab4-b84e-4777-ddf6-0ca085fca589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        }
      },
      "source": [
        "model = CTransformer(emb=256, heads=16, depth=12, seq_length=mx, num_tokens=50000, num_classes=20, max_pool=True)\n",
        "opt = torch.optim.Adam(lr=0.1, params=model.parameters())\n",
        "sch = torch.optim.lr_scheduler.LambdaLR(opt, lambda i: min(i / (10_000 / 4), 1.0))\n",
        "model = model.to(device)\n",
        "seen = 0\n",
        "for e in range(10): # epochs\n",
        "\n",
        "    print(f'\\n epoch {e}')\n",
        "    model.train(True)\n",
        "\n",
        "    for batch in tqdm.tqdm(train_iter):\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        input = batch.text[0].to(device)\n",
        "        label = (batch.units_clean - 1).to(device)\n",
        "        \n",
        "        if input.size(1) > mx:\n",
        "            input = input[:, :mx]\n",
        "        out = model(input)\n",
        "        loss = F.nll_loss(out, label)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # clip gradients\n",
        "        # - If the total gradient vector has a length > 1, we clip it back down to 1.\n",
        "        if 1.0 > 0.0: # gradient_clipping arg default=1.0\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        opt.step()\n",
        "        sch.step()\n",
        "\n",
        "        seen += input.size(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      \n",
        "        model.train(False)\n",
        "        tot, cor= 0.0, 0.0\n",
        "\n",
        "        for batch in val_iter:\n",
        "\n",
        "            input = batch.text[0].to(device)\n",
        "            label = (batch.units_clean - 1).to(device)\n",
        "            \n",
        "            if input.size(1) > mx:\n",
        "                input = input[:, :mx]\n",
        "            out = model(input).argmax(dim=1)\n",
        "\n",
        "            tot += float(input.size(0))\n",
        "            cor += float((label == out).sum().item())\n",
        "\n",
        "        acc = cor / tot\n",
        "        print(f'-- {\"validation\"} accuracy {acc:.3}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [24:34<00:00, 22.30it/s]\n",
            "  0%|          | 1/32891 [00:00<1:47:44,  5.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.325\n",
            "\n",
            " epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [24:45<00:00, 22.14it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.172\n",
            "\n",
            " epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [25:43<00:00, 21.30it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.325\n",
            "\n",
            " epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [26:17<00:00, 20.86it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.325\n",
            "\n",
            " epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [26:16<00:00, 20.86it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.325\n",
            "\n",
            " epoch 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [25:45<00:00, 21.28it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.239\n",
            "\n",
            " epoch 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [25:53<00:00, 21.18it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.325\n",
            "\n",
            " epoch 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [26:15<00:00, 20.88it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.172\n",
            "\n",
            " epoch 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [26:33<00:00, 20.64it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.0078\n",
            "\n",
            " epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [26:17<00:00, 20.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db8K9BsJs-JT",
        "outputId": "5e9969e6-35cb-4ab1-f445-01c53fa1b53d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        }
      },
      "source": [
        "model = CTransformer(emb=128, heads=16, depth=6, seq_length=mx, num_tokens=50000, num_classes=20, max_pool=True)\n",
        "opt = torch.optim.Adam(lr=0.01, params=model.parameters())\n",
        "sch = torch.optim.lr_scheduler.LambdaLR(opt, lambda i: min(i / (10_000 / 4), 1.0))\n",
        "model = model.to(device)\n",
        "seen = 0\n",
        "for e in range(10): # epochs\n",
        "\n",
        "    print(f'\\n epoch {e}')\n",
        "    model.train(True)\n",
        "\n",
        "    for batch in tqdm.tqdm(train_iter):\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        input = batch.text[0].to(device)\n",
        "        label = (batch.units_clean - 1).to(device)\n",
        "        \n",
        "        if input.size(1) > mx:\n",
        "            input = input[:, :mx]\n",
        "        out = model(input)\n",
        "        loss = F.nll_loss(out, label)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # clip gradients\n",
        "        # - If the total gradient vector has a length > 1, we clip it back down to 1.\n",
        "        if 1.0 > 0.0: # gradient_clipping arg default=1.0\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        opt.step()\n",
        "        sch.step()\n",
        "\n",
        "        seen += input.size(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      \n",
        "        model.train(False)\n",
        "        tot, cor= 0.0, 0.0\n",
        "\n",
        "        for batch in val_iter:\n",
        "\n",
        "            input = batch.text[0].to(device)\n",
        "            label = (batch.units_clean - 1).to(device)\n",
        "            \n",
        "            if input.size(1) > mx:\n",
        "                input = input[:, :mx]\n",
        "            out = model(input).argmax(dim=1)\n",
        "\n",
        "            tot += float(input.size(0))\n",
        "            cor += float((label == out).sum().item())\n",
        "\n",
        "        acc = cor / tot\n",
        "        print(f'-- {\"validation\"} accuracy {acc:.3}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [13:30<00:00, 40.58it/s]\n",
            "  0%|          | 1/32891 [00:00<1:47:44,  5.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.325\n",
            "\n",
            " epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [13:30<00:00, 40.57it/s]\n",
            "  0%|          | 1/32891 [00:00<1:47:26,  5.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.325\n",
            "\n",
            " epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [13:19<00:00, 41.14it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.325\n",
            "\n",
            " epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [13:42<00:00, 39.98it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.325\n",
            "\n",
            " epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [13:35<00:00, 40.35it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.325\n",
            "\n",
            " epoch 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [13:36<00:00, 40.28it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.325\n",
            "\n",
            " epoch 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [13:27<00:00, 40.75it/s]\n",
            "  0%|          | 1/32891 [00:00<1:48:46,  5.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.325\n",
            "\n",
            " epoch 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [13:22<00:00, 41.01it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.325\n",
            "\n",
            " epoch 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [13:23<00:00, 40.93it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.325\n",
            "\n",
            " epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [13:04<00:00, 41.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g3GqIeKtHCK",
        "outputId": "7c7bf6bb-6ce0-4c6b-f740-fa0ee38895d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        }
      },
      "source": [
        "model = CTransformer(emb=256, heads=8, depth=6, seq_length=mx, num_tokens=50000, num_classes=20, max_pool=True)\n",
        "opt = torch.optim.Adam(lr=0.001, params=model.parameters())\n",
        "sch = torch.optim.lr_scheduler.LambdaLR(opt, lambda i: min(i / (10_000 / 4), 1.0))\n",
        "model = model.to(device)\n",
        "seen = 0\n",
        "for e in range(10): # epochs\n",
        "\n",
        "    print(f'\\n epoch {e}')\n",
        "    model.train(True)\n",
        "\n",
        "    for batch in tqdm.tqdm(train_iter):\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        input = batch.text[0].to(device)\n",
        "        label = (batch.units_clean - 1).to(device)\n",
        "        \n",
        "        if input.size(1) > mx:\n",
        "            input = input[:, :mx]\n",
        "        out = model(input)\n",
        "        loss = F.nll_loss(out, label)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # clip gradients\n",
        "        # - If the total gradient vector has a length > 1, we clip it back down to 1.\n",
        "        if 1.0 > 0.0: # gradient_clipping arg default=1.0\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        opt.step()\n",
        "        sch.step()\n",
        "\n",
        "        seen += input.size(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      \n",
        "        model.train(False)\n",
        "        tot, cor= 0.0, 0.0\n",
        "\n",
        "        for batch in val_iter:\n",
        "\n",
        "            input = batch.text[0].to(device)\n",
        "            label = (batch.units_clean - 1).to(device)\n",
        "            \n",
        "            if input.size(1) > mx:\n",
        "                input = input[:, :mx]\n",
        "            out = model(input).argmax(dim=1)\n",
        "\n",
        "            tot += float(input.size(0))\n",
        "            cor += float((label == out).sum().item())\n",
        "\n",
        "        acc = cor / tot\n",
        "        print(f'-- {\"validation\"} accuracy {acc:.3}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/32891 [00:00<1:47:34,  5.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [13:19<00:00, 41.15it/s]\n",
            "  0%|          | 1/32891 [00:00<1:46:39,  5.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.808\n",
            "\n",
            " epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [13:17<00:00, 41.22it/s]\n",
            "  0%|          | 1/32891 [00:00<1:46:37,  5.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.838\n",
            "\n",
            " epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [13:22<00:00, 41.00it/s]\n",
            "  0%|          | 1/32891 [00:00<1:47:07,  5.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.853\n",
            "\n",
            " epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [13:32<00:00, 40.50it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.881\n",
            "\n",
            " epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [14:10<00:00, 38.67it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.882\n",
            "\n",
            " epoch 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [14:26<00:00, 37.94it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.888\n",
            "\n",
            " epoch 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [14:24<00:00, 38.05it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.891\n",
            "\n",
            " epoch 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [14:20<00:00, 38.24it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.897\n",
            "\n",
            " epoch 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [14:26<00:00, 37.96it/s]\n",
            "  0%|          | 0/32891 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.893\n",
            "\n",
            " epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32891/32891 [14:24<00:00, 38.06it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- validation accuracy 0.897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1Z2UsdxtMEK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}